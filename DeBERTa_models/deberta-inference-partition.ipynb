{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d445c42",
   "metadata": {},
   "source": [
    "# DeBERTa Inference Notebook with Partitioning \n",
    "\n",
    "This notebook serves as the main runfile for making inferences on DeBERTa models using partitioning. The parameters that can be changed are the threshold for determining if something is a non-PII or not. Otherwise, make sure to import the correct model path for the most updated DeBERTa partitioning model.\n",
    "\n",
    "Note that we tested models by making inferences and submitting these inferences to kaggle for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c64d4f0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-02T19:39:30.869480Z",
     "iopub.status.busy": "2024-05-02T19:39:30.868598Z",
     "iopub.status.idle": "2024-05-02T19:39:31.518562Z",
     "shell.execute_reply": "2024-05-02T19:39:31.517398Z"
    },
    "papermill": {
     "duration": 0.659793,
     "end_time": "2024-05-02T19:39:31.520930",
     "exception": false,
     "start_time": "2024-05-02T19:39:30.861137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/deberta-model-partition-usethis/__results__.html\n",
      "/kaggle/input/deberta-model-partition-usethis/__notebook__.ipynb\n",
      "/kaggle/input/deberta-model-partition-usethis/__output__.json\n",
      "/kaggle/input/deberta-model-partition-usethis/custom.css\n",
      "/kaggle/input/deberta-model-partition-usethis/output/checkpoint-500/spm.model\n",
      "/kaggle/input/deberta-model-partition-usethis/output/checkpoint-500/config.json\n",
      "/kaggle/input/deberta-model-partition-usethis/output/checkpoint-500/trainer_state.json\n",
      "/kaggle/input/deberta-model-partition-usethis/output/checkpoint-500/training_args.bin\n",
      "/kaggle/input/deberta-model-partition-usethis/output/checkpoint-500/tokenizer.json\n",
      "/kaggle/input/deberta-model-partition-usethis/output/checkpoint-500/tokenizer_config.json\n",
      "/kaggle/input/deberta-model-partition-usethis/output/checkpoint-500/scheduler.pt\n",
      "/kaggle/input/deberta-model-partition-usethis/output/checkpoint-500/model.safetensors\n",
      "/kaggle/input/deberta-model-partition-usethis/output/checkpoint-500/special_tokens_map.json\n",
      "/kaggle/input/deberta-model-partition-usethis/output/checkpoint-500/optimizer.pt\n",
      "/kaggle/input/deberta-model-partition-usethis/output/checkpoint-500/rng_state.pth\n",
      "/kaggle/input/deberta-model-partition-usethis/output/checkpoint-500/added_tokens.json\n",
      "/kaggle/input/deberta-model-partition-usethis/deberta_partition/spm.model\n",
      "/kaggle/input/deberta-model-partition-usethis/deberta_partition/config.json\n",
      "/kaggle/input/deberta-model-partition-usethis/deberta_partition/training_args.bin\n",
      "/kaggle/input/deberta-model-partition-usethis/deberta_partition/tokenizer.json\n",
      "/kaggle/input/deberta-model-partition-usethis/deberta_partition/tokenizer_config.json\n",
      "/kaggle/input/deberta-model-partition-usethis/deberta_partition/model.safetensors\n",
      "/kaggle/input/deberta-model-partition-usethis/deberta_partition/special_tokens_map.json\n",
      "/kaggle/input/deberta-model-partition-usethis/deberta_partition/added_tokens.json\n",
      "/kaggle/input/pii-detection-removal-from-educational-data/sample_submission.csv\n",
      "/kaggle/input/pii-detection-removal-from-educational-data/train.json\n",
      "/kaggle/input/pii-detection-removal-from-educational-data/test.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2529445d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T19:39:31.533038Z",
     "iopub.status.busy": "2024-05-02T19:39:31.532650Z",
     "iopub.status.idle": "2024-05-02T19:39:31.536900Z",
     "shell.execute_reply": "2024-05-02T19:39:31.536048Z"
    },
    "papermill": {
     "duration": 0.012046,
     "end_time": "2024-05-02T19:39:31.538765",
     "exception": false,
     "start_time": "2024-05-02T19:39:31.526719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INFERENCE_MAX_LENGTH = 2048\n",
    "\n",
    "# change to local model path \n",
    "model_path = '/kaggle/input/deberta-model-partition-usethis/deberta_partition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e298f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T19:39:31.550632Z",
     "iopub.status.busy": "2024-05-02T19:39:31.550335Z",
     "iopub.status.idle": "2024-05-02T19:39:48.337278Z",
     "shell.execute_reply": "2024-05-02T19:39:48.336481Z"
    },
    "papermill": {
     "duration": 16.795455,
     "end_time": "2024-05-02T19:39:48.339520",
     "exception": false,
     "start_time": "2024-05-02T19:39:31.544065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 19:39:40.493108: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-02 19:39:40.493211: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-02 19:39:40.583154: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import json\n",
    "import argparse\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification\n",
    "from datasets import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "956c7fe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T19:39:48.352093Z",
     "iopub.status.busy": "2024-05-02T19:39:48.351525Z",
     "iopub.status.idle": "2024-05-02T19:39:48.365966Z",
     "shell.execute_reply": "2024-05-02T19:39:48.365285Z"
    },
    "papermill": {
     "duration": 0.022715,
     "end_time": "2024-05-02T19:39:48.367923",
     "exception": false,
     "start_time": "2024-05-02T19:39:48.345208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load test data (assuming locally stored in the correct format)\n",
    "data = json.load(open(\"/kaggle/input/pii-detection-removal-from-educational-data/test.json\"))\n",
    "df_test = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f66e0170",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T19:39:48.379123Z",
     "iopub.status.busy": "2024-05-02T19:39:48.378854Z",
     "iopub.status.idle": "2024-05-02T19:39:48.386247Z",
     "shell.execute_reply": "2024-05-02T19:39:48.385380Z"
    },
    "papermill": {
     "duration": 0.015094,
     "end_time": "2024-05-02T19:39:48.388163",
     "exception": false,
     "start_time": "2024-05-02T19:39:48.373069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reconstruct(batch): \n",
    "    text = []\n",
    "    token_map = []\n",
    "    \n",
    "    idx = 0\n",
    "    \n",
    "    for t, ws in zip(batch[\"tokens\"], batch[\"trailing_whitespace\"]):\n",
    "    \n",
    "        text.append(t)\n",
    "        token_map.extend([idx]*len(t))\n",
    "        if ws:\n",
    "            text.append(\" \")\n",
    "            token_map.append(-1)\n",
    "        \n",
    "        idx += 1\n",
    "            \n",
    "                \n",
    "    return text, token_map\n",
    "\n",
    "def tokenize(batch, tokenizer):\n",
    "    \n",
    "    text,token_map = reconstruct(batch)\n",
    "    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, truncation=False, max_length=INFERENCE_MAX_LENGTH)\n",
    "\n",
    "    return tokenized.input_ids, tokenized.attention_mask, tokenized.offset_mapping, token_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a0dabfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T19:39:48.399868Z",
     "iopub.status.busy": "2024-05-02T19:39:48.399604Z",
     "iopub.status.idle": "2024-05-02T19:39:48.409582Z",
     "shell.execute_reply": "2024-05-02T19:39:48.408847Z"
    },
    "papermill": {
     "duration": 0.018239,
     "end_time": "2024-05-02T19:39:48.411704",
     "exception": false,
     "start_time": "2024-05-02T19:39:48.393465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_files(df, MAX_LENGTH): \n",
    "    df_split = pd.DataFrame(columns = ['document', 'full_text', 'tokens', 'trailing_whitespace', 'input_ids', 'attention_mask', 'offset_mapping', 'token_map'])\n",
    "\n",
    "    for index, row in df.iterrows(): \n",
    "        document = df.loc[index].document\n",
    "        full_text = df.loc[index].full_text\n",
    "        tokens = df.loc[index].tokens\n",
    "        trailing_whitespace = df.loc[index].trailing_whitespace\n",
    "        input_ids = df.loc[index].input_ids\n",
    "        attention_mask = df.loc[index].attention_mask\n",
    "        offset_mapping = df.loc[index].offset_mapping\n",
    "        token_map = df.loc[index].token_map\n",
    "        length = len(input_ids)\n",
    "        num_rows = -(length // -MAX_LENGTH)       \n",
    "        for i in range(num_rows): \n",
    "            new_input_ids = input_ids[i*MAX_LENGTH: (i + 1)* MAX_LENGTH]\n",
    "            new_attention_mask = attention_mask[i*MAX_LENGTH: (i + 1)* MAX_LENGTH]\n",
    "            new_offset_mapping = offset_mapping[i*MAX_LENGTH: (i + 1)* MAX_LENGTH]\n",
    "            df_split = df_split._append({'document': document, 'full_text': full_text, 'tokens': tokens, 'trailing_whitespace': trailing_whitespace, 'input_ids': new_input_ids, 'attention_mask': new_attention_mask, 'offset_mapping': new_offset_mapping, 'token_map': token_map}, ignore_index=True)\n",
    "    \n",
    "    return df_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35aa011a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T19:39:48.423875Z",
     "iopub.status.busy": "2024-05-02T19:39:48.423609Z",
     "iopub.status.idle": "2024-05-02T19:39:48.825682Z",
     "shell.execute_reply": "2024-05-02T19:39:48.824903Z"
    },
    "papermill": {
     "duration": 0.410721,
     "end_time": "2024-05-02T19:39:48.828066",
     "exception": false,
     "start_time": "2024-05-02T19:39:48.417345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "df_test[['input_ids', 'attention_mask', 'offset_mapping', 'token_map']] = df_test.apply(lambda row: tokenize(row, tokenizer), axis='columns', result_type='expand')\n",
    "df_tt = split_files(df_test, INFERENCE_MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecd4eeb",
   "metadata": {
    "papermill": {
     "duration": 0.004957,
     "end_time": "2024-05-02T19:39:48.838743",
     "exception": false,
     "start_time": "2024-05-02T19:39:48.833786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "255795ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T19:39:48.850624Z",
     "iopub.status.busy": "2024-05-02T19:39:48.850098Z",
     "iopub.status.idle": "2024-05-02T19:39:48.903786Z",
     "shell.execute_reply": "2024-05-02T19:39:48.903107Z"
    },
    "papermill": {
     "duration": 0.061637,
     "end_time": "2024-05-02T19:39:48.905633",
     "exception": false,
     "start_time": "2024-05-02T19:39:48.843996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds =  Dataset.from_pandas(df_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a1b5756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T19:39:48.916559Z",
     "iopub.status.busy": "2024-05-02T19:39:48.916288Z",
     "iopub.status.idle": "2024-05-02T19:39:53.949756Z",
     "shell.execute_reply": "2024-05-02T19:39:53.948724Z"
    },
    "papermill": {
     "duration": 5.041603,
     "end_time": "2024-05-02T19:39:53.952162",
     "exception": false,
     "start_time": "2024-05-02T19:39:48.910559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)\n",
    "args = TrainingArguments(\n",
    "    \".\", \n",
    "    per_device_eval_batch_size=1, \n",
    "    report_to=\"none\",\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=args, \n",
    "    data_collator=collator, \n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4fb7dfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T19:39:53.964715Z",
     "iopub.status.busy": "2024-05-02T19:39:53.964418Z",
     "iopub.status.idle": "2024-05-02T19:39:58.084734Z",
     "shell.execute_reply": "2024-05-02T19:39:58.083930Z"
    },
    "papermill": {
     "duration": 4.12901,
     "end_time": "2024-05-02T19:39:58.086756",
     "exception": false,
     "start_time": "2024-05-02T19:39:53.957746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(ds).predictions\n",
    "pred_softmax = np.exp(predictions) / np.sum(np.exp(predictions), axis = 2).reshape(predictions.shape[0],predictions.shape[1],1)\n",
    "\n",
    "config = json.load(open(Path(model_path) / \"config.json\"))\n",
    "id2label = config[\"id2label\"]\n",
    "preds = predictions.argmax(-1)\n",
    "preds_without_O = pred_softmax[:,:,:12].argmax(-1)\n",
    "O_preds = pred_softmax[:,:,12]\n",
    "\n",
    "threshold = 0.99\n",
    "preds_final = np.where(O_preds < threshold, preds_without_O , preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "380abb54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T19:39:58.098589Z",
     "iopub.status.busy": "2024-05-02T19:39:58.098305Z",
     "iopub.status.idle": "2024-05-02T19:39:58.193323Z",
     "shell.execute_reply": "2024-05-02T19:39:58.192487Z"
    },
    "papermill": {
     "duration": 0.10336,
     "end_time": "2024-05-02T19:39:58.195521",
     "exception": false,
     "start_time": "2024-05-02T19:39:58.092161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "triplets = []\n",
    "document, token, label, token_str = [], [], [], []\n",
    "for p, token_map, offsets, tokens, doc in zip(preds_final, ds[\"token_map\"], ds[\"offset_mapping\"], ds[\"tokens\"], ds[\"document\"]):\n",
    "\n",
    "    for token_pred, (start_idx, end_idx) in zip(p, offsets):\n",
    "        label_pred = id2label[str(token_pred)]\n",
    "\n",
    "        if start_idx + end_idx == 0: continue\n",
    "\n",
    "        if token_map[start_idx] == -1:\n",
    "            start_idx += 1\n",
    "\n",
    "        # ignore \"\\n\\n\"\n",
    "        while start_idx < len(token_map) and tokens[token_map[start_idx]].isspace():\n",
    "            start_idx += 1\n",
    "\n",
    "        if start_idx >= len(token_map): break\n",
    "\n",
    "        token_id = token_map[start_idx]\n",
    "\n",
    "        # ignore \"O\" predictions and whitespace preds\n",
    "        if label_pred != \"O\" and token_id != -1:\n",
    "            triplet = (label_pred, token_id, tokens[token_id])\n",
    "\n",
    "            if triplet not in triplets:\n",
    "                document.append(doc)\n",
    "                token.append(token_id)\n",
    "                label.append(label_pred)\n",
    "                token_str.append(tokens[token_id])\n",
    "                triplets.append(triplet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8fc4c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T02:08:48.681877Z",
     "iopub.status.busy": "2024-04-30T02:08:48.681371Z",
     "iopub.status.idle": "2024-04-30T02:08:48.690567Z",
     "shell.execute_reply": "2024-04-30T02:08:48.689223Z",
     "shell.execute_reply.started": "2024-04-30T02:08:48.681839Z"
    },
    "papermill": {
     "duration": 0.005723,
     "end_time": "2024-05-02T19:39:58.206998",
     "exception": false,
     "start_time": "2024-05-02T19:39:58.201275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a6e21cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T19:39:58.219605Z",
     "iopub.status.busy": "2024-05-02T19:39:58.219290Z",
     "iopub.status.idle": "2024-05-02T19:39:58.238080Z",
     "shell.execute_reply": "2024-05-02T19:39:58.237136Z"
    },
    "papermill": {
     "duration": 0.027299,
     "end_time": "2024-05-02T19:39:58.240068",
     "exception": false,
     "start_time": "2024-05-02T19:39:58.212769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>token_str</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>482</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>483</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>741</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>742</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Diego</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Estrada</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>464</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Diego</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>465</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Estrada</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Gilberto</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Gamboa</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Sindy</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Samaca</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nadine</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Born</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>86</td>\n",
       "      <td>6</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Eladio</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>86</td>\n",
       "      <td>7</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Amaya</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Silvia</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Villalobos</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>104</td>\n",
       "      <td>8</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Sakir</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>104</td>\n",
       "      <td>9</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Ahmad</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Francisco</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>112</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Ferreira</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>123</td>\n",
       "      <td>32</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Stefano</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>123</td>\n",
       "      <td>33</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Lovato</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    document  token           label   token_str  row_id\n",
       "0          7      9  B-NAME_STUDENT    Nathalie       0\n",
       "1          7     10  I-NAME_STUDENT       Sylla       1\n",
       "2          7    482  B-NAME_STUDENT    Nathalie       2\n",
       "3          7    483  I-NAME_STUDENT       Sylla       3\n",
       "4          7    741  B-NAME_STUDENT    Nathalie       4\n",
       "5          7    742  I-NAME_STUDENT       Sylla       5\n",
       "6         10      0  B-NAME_STUDENT       Diego       6\n",
       "7         10      1  I-NAME_STUDENT     Estrada       7\n",
       "8         10    464  B-NAME_STUDENT       Diego       8\n",
       "9         10    465  I-NAME_STUDENT     Estrada       9\n",
       "10        16      4  B-NAME_STUDENT    Gilberto      10\n",
       "11        16      5  I-NAME_STUDENT      Gamboa      11\n",
       "12        20      5  B-NAME_STUDENT       Sindy      12\n",
       "13        20      6  I-NAME_STUDENT      Samaca      13\n",
       "14        56     12  B-NAME_STUDENT      Nadine      14\n",
       "15        56     13  I-NAME_STUDENT        Born      15\n",
       "16        86      6  B-NAME_STUDENT      Eladio      16\n",
       "17        86      7  I-NAME_STUDENT       Amaya      17\n",
       "18        93      0  B-NAME_STUDENT      Silvia      18\n",
       "19        93      1  I-NAME_STUDENT  Villalobos      19\n",
       "20       104      8  B-NAME_STUDENT       Sakir      20\n",
       "21       104      9  I-NAME_STUDENT       Ahmad      21\n",
       "22       112      5  B-NAME_STUDENT   Francisco      22\n",
       "23       112      6  I-NAME_STUDENT    Ferreira      23\n",
       "24       123     32  B-NAME_STUDENT     Stefano      24\n",
       "25       123     33  I-NAME_STUDENT      Lovato      25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"document\": document,\n",
    "    \"token\": token,\n",
    "    \"label\": label,\n",
    "    \"token_str\": token_str\n",
    "})\n",
    "df[\"row_id\"] = list(range(len(df)))\n",
    "display(df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b8e7d89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T19:39:58.253014Z",
     "iopub.status.busy": "2024-05-02T19:39:58.252713Z",
     "iopub.status.idle": "2024-05-02T19:39:58.265023Z",
     "shell.execute_reply": "2024-05-02T19:39:58.264314Z"
    },
    "papermill": {
     "duration": 0.021035,
     "end_time": "2024-05-02T19:39:58.267036",
     "exception": false,
     "start_time": "2024-05-02T19:39:58.246001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[[\"row_id\", \"document\", \"token\", \"label\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e88945e",
   "metadata": {
    "papermill": {
     "duration": 0.005637,
     "end_time": "2024-05-02T19:39:58.279661",
     "exception": false,
     "start_time": "2024-05-02T19:39:58.274024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    },
    {
     "sourceId": 175312199,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33.091086,
   "end_time": "2024-05-02T19:40:01.327895",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-02T19:39:28.236809",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
