{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoBERTa Model with Partitioning\n",
    "This notebook serves as the main run file for RoBERTa models using partitioning to preprocess the data\n",
    "There are several things that one can change in this file for each run: \n",
    "1. Penalty for loss function \n",
    "2. Can alter truncate function to change the truncation of tokenization\n",
    "3. Training parameters such as epochs, learning rate, etc. \n",
    "4. Training on data which has been split into train/test sets or training on full dataset (i.e. after final model has been chosen). To do this, change `evaluation_strategy` to `no`, and in the `trainer=Trainer()`, delete `test_ds=...` and change `train_ds=...` to `train_ds=ds`. \n",
    "*Note that this notebook was never used in testing as preliminary tests indicate that such a model performs poorly, however this notebook serves as a way to recreate this poor performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-02T17:04:37.160515Z",
     "iopub.status.busy": "2024-05-02T17:04:37.160248Z",
     "iopub.status.idle": "2024-05-02T17:04:38.288807Z",
     "shell.execute_reply": "2024-05-02T17:04:38.287907Z",
     "shell.execute_reply.started": "2024-05-02T17:04:37.160491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/data-exploration/deberta_test.csv\n",
      "/kaggle/input/data-exploration/roberta_test.csv\n",
      "/kaggle/input/data-exploration/roberta_train.csv\n",
      "/kaggle/input/data-exploration/__results__.html\n",
      "/kaggle/input/data-exploration/docs2cut.txt\n",
      "/kaggle/input/data-exploration/deberta_train.csv\n",
      "/kaggle/input/data-exploration/__notebook__.ipynb\n",
      "/kaggle/input/data-exploration/__output__.json\n",
      "/kaggle/input/data-exploration/train.csv\n",
      "/kaggle/input/data-exploration/test.csv\n",
      "/kaggle/input/data-exploration/custom.css\n",
      "/kaggle/input/pii-detection-removal-from-educational-data/sample_submission.csv\n",
      "/kaggle/input/pii-detection-removal-from-educational-data/train.json\n",
      "/kaggle/input/pii-detection-removal-from-educational-data/test.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T01:40:18.963855Z",
     "iopub.status.busy": "2024-05-02T01:40:18.963527Z",
     "iopub.status.idle": "2024-05-02T01:40:38.431223Z",
     "shell.execute_reply": "2024-05-02T01:40:38.430138Z",
     "shell.execute_reply.started": "2024-05-02T01:40:18.963832Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 01:40:35.981392: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-02 01:40:35.981441: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-02 01:40:35.982915: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval evaluate -q\n",
    "import json\n",
    "import argparse\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "import torch\n",
    "from transformers import AutoTokenizer,AutoModelForTokenClassification,Trainer, TrainingArguments, AutoConfig, DataCollatorForTokenClassification, TrainerCallback\n",
    "import evaluate\n",
    "from datasets import Dataset, features\n",
    "import copy\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepararations for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T01:40:38.433944Z",
     "iopub.status.busy": "2024-05-02T01:40:38.432734Z",
     "iopub.status.idle": "2024-05-02T01:40:38.438666Z",
     "shell.execute_reply": "2024-05-02T01:40:38.437740Z",
     "shell.execute_reply.started": "2024-05-02T01:40:38.433902Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model Settings from Hugging Face: Path, Length, Output Directory\n",
    "TRAINING_MODEL_PATH = \"FacebookAI/roberta-base\"\n",
    "TRAINING_MAX_LENGTH = 512\n",
    "OUTPUT_DIR = \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T01:40:38.442019Z",
     "iopub.status.busy": "2024-05-02T01:40:38.441458Z",
     "iopub.status.idle": "2024-05-02T01:40:42.901413Z",
     "shell.execute_reply": "2024-05-02T01:40:42.900463Z",
     "shell.execute_reply.started": "2024-05-02T01:40:38.441800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['document', 'deberta_input_ids', 'deberta_attention_mask',\n",
      "       'deberta_offset_mapping', 'deberta_token_labels', 'deberta_length'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(open('/kaggle/input/data-exploration/train.csv'))\n",
    "test = pd.read_csv(open('/kaggle/input/data-exploration/test.csv'))\n",
    "train = train[['document', 'deberta_input_ids',\n",
    "       'deberta_attention_mask', 'deberta_offset_mapping',\n",
    "       'deberta_token_labels', 'deberta_length']]\n",
    "test = test[['document', 'deberta_input_ids',\n",
    "       'deberta_attention_mask', 'deberta_offset_mapping',\n",
    "       'deberta_token_labels', 'deberta_length']]\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T01:40:42.902993Z",
     "iopub.status.busy": "2024-05-02T01:40:42.902622Z",
     "iopub.status.idle": "2024-05-02T01:42:04.076896Z",
     "shell.execute_reply": "2024-05-02T01:42:04.076114Z",
     "shell.execute_reply.started": "2024-05-02T01:40:42.902964Z"
    }
   },
   "outputs": [],
   "source": [
    "train['roberta_input_ids'] = train['roberta_input_ids'].apply(literal_eval)\n",
    "train['roberta_attention_mask'] = train['roberta_attention_mask'].apply(literal_eval)\n",
    "train['roberta_offset_mapping'] = train['roberta_offset_mapping'].apply(literal_eval)\n",
    "train['roberta_token_labels'] = train['roberta_token_labels'].apply(literal_eval)\n",
    "test['roberta_input_ids'] = test['roberta_input_ids'].apply(literal_eval)\n",
    "test['roberta_attention_mask'] = test['roberta_attention_mask'].apply(literal_eval)\n",
    "test['roberta_offset_mapping'] = test['roberta_offset_mapping'].apply(literal_eval)\n",
    "test['roberta_token_labels'] = test['roberta_token_labels'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T01:42:04.078828Z",
     "iopub.status.busy": "2024-05-02T01:42:04.078118Z",
     "iopub.status.idle": "2024-05-02T01:42:04.777571Z",
     "shell.execute_reply": "2024-05-02T01:42:04.776742Z",
     "shell.execute_reply.started": "2024-05-02T01:42:04.078792Z"
    }
   },
   "outputs": [],
   "source": [
    "def truncate(ls): \n",
    "    # Normal truncation\n",
    "    # return(ls[:TRAINING_MAX_LENGTH])\n",
    "    \n",
    "    # Optimized truncation\n",
    "    length = len(ls)\n",
    "    if (length > TRAINING_MAX_LENGTH): \n",
    "        cutoff = 121\n",
    "        return(ls[:cutoff] + ls[-(TRAINING_MAX_LENGTH-cutoff):])\n",
    "    else: return ls\n",
    "\n",
    "train['input_ids'] = train['roberta_input_ids'].apply(truncate)\n",
    "train['attention_mask'] = train['roberta_attention_mask'].apply(truncate)\n",
    "train['offset_mapping'] = train['roberta_offset_mapping'].apply(truncate)\n",
    "train['labels'] = train['roberta_token_labels'].apply(truncate)\n",
    "test['input_ids'] = test['roberta_input_ids'].apply(truncate)\n",
    "test['attention_mask'] = test['roberta_attention_mask'].apply(truncate)\n",
    "test['offset_mapping'] = test['roberta_offset_mapping'].apply(truncate)\n",
    "test['labels'] = test['roberta_token_labels'].apply(truncate)\n",
    "    \n",
    "train = train.drop(['roberta_input_ids', 'roberta_attention_mask','roberta_offset_mapping', \n",
    "                     'roberta_token_labels', 'roberta_length'], axis = 1)\n",
    "test = test.drop(['roberta_input_ids', 'roberta_attention_mask','roberta_offset_mapping', \n",
    "                     'roberta_token_labels', 'roberta_length'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T01:42:04.778955Z",
     "iopub.status.busy": "2024-05-02T01:42:04.778657Z",
     "iopub.status.idle": "2024-05-02T01:42:10.821999Z",
     "shell.execute_reply": "2024-05-02T01:42:10.820865Z",
     "shell.execute_reply.started": "2024-05-02T01:42:04.778931Z"
    }
   },
   "outputs": [],
   "source": [
    "ds_train = Dataset.from_pandas(train)\n",
    "ds_test = Dataset.from_pandas(test)\n",
    "\n",
    "# For final model\n",
    "#all_data = pd.concat([train, test], ignore_index=True, sort=False)\n",
    "#ds = Dataset.from_pandas(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T01:42:10.833480Z",
     "iopub.status.busy": "2024-05-02T01:42:10.833139Z",
     "iopub.status.idle": "2024-05-02T01:42:10.841193Z",
     "shell.execute_reply": "2024-05-02T01:42:10.840180Z",
     "shell.execute_reply.started": "2024-05-02T01:42:10.833455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-EMAIL', 'B-ID_NUM', 'B-NAME_STUDENT', 'B-PHONE_NUM', 'B-STREET_ADDRESS', 'B-URL_PERSONAL', 'B-USERNAME', 'I-ID_NUM', 'I-NAME_STUDENT', 'I-PHONE_NUM', 'I-STREET_ADDRESS', 'I-URL_PERSONAL', 'O']\n"
     ]
    }
   ],
   "source": [
    "# Obtain all possible labels, along with a map between them and their ids\n",
    "LABELS = ['B-EMAIL', 'B-ID_NUM', 'B-NAME_STUDENT', 'B-PHONE_NUM', 'B-STREET_ADDRESS', \n",
    "          'B-URL_PERSONAL', 'B-USERNAME', 'I-ID_NUM', 'I-NAME_STUDENT', 'I-PHONE_NUM', \n",
    "          'I-STREET_ADDRESS', 'I-URL_PERSONAL', 'O']\n",
    "\n",
    "label2id = {l:i for i, l in enumerate(LABELS)}\n",
    "id2label = {i:l for i, l in enumerate(LABELS)}\n",
    "print(LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T01:42:10.842817Z",
     "iopub.status.busy": "2024-05-02T01:42:10.842500Z",
     "iopub.status.idle": "2024-05-02T01:42:10.858703Z",
     "shell.execute_reply": "2024-05-02T01:42:10.857788Z",
     "shell.execute_reply.started": "2024-05-02T01:42:10.842792Z"
    }
   },
   "outputs": [],
   "source": [
    "# METRICS\n",
    "\n",
    "# Investigate adding some metrics to compute finer accuracies\n",
    "\n",
    "# now let's define the metrics we care about \n",
    "from seqeval.metrics import recall_score, precision_score\n",
    "\n",
    "def compute_metrics(p, all_labels):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [all_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [all_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    recall = recall_score(true_labels, true_predictions)\n",
    "    precision = precision_score(true_labels, true_predictions)\n",
    "    f5_score = (1 + 5*5) * recall * precision / (5*5*precision + recall)\n",
    "    \n",
    "    results = {\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f5': f5_score\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T01:42:10.860275Z",
     "iopub.status.busy": "2024-05-02T01:42:10.859913Z",
     "iopub.status.idle": "2024-05-02T01:42:11.307706Z",
     "shell.execute_reply": "2024-05-02T01:42:11.306738Z",
     "shell.execute_reply.started": "2024-05-02T01:42:10.860240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.0500], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Implement custom loss function \n",
    "import torch.nn.functional as F\n",
    "\n",
    "penalty = .05 # raise this to penalize guesses of PII for non-PII labels more\n",
    "wts = torch.ones(len(LABELS))\n",
    "wts[-1] = penalty # weight last class\n",
    "wts = wts.to(device='cuda')\n",
    "print('weights:', wts)\n",
    "\n",
    "def custom_loss(preds, trues):\n",
    "    \"\"\"\n",
    "    cross-entropy loss, but if a token is NOT PII, the loss for the \n",
    "    corresponding prediction, instead of being -logsoftmax(logit), \n",
    "    is equal to penalty. \n",
    "    \n",
    "    This function will be applied to (logits, labels), i.e. we will\n",
    "    call custom_loss(logits, labels) in the training step; logits will \n",
    "    have shape bs x max_seq_len x num_labels, labels will have shape \n",
    "    bs x max_seq_len. \n",
    "    \n",
    "    It seems we can use just the built-in 'weight' parameter passed\n",
    "    to the cross_entropy function\n",
    "    \"\"\"\n",
    "    loss = F.cross_entropy(preds.permute(0,2,1), trues, \n",
    "                           weight=wts)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# subclass Trainer \n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        # inputs is a dict with keys 'input_ids', a tensor representing the \n",
    "        # input sequence as a str of ints which are the vocabulary indices; \n",
    "        # token_type_ids and attention_mask, which seem irrelevant for the \n",
    "        # compute_loss function; and 'labels' which is the true values       \n",
    "        labels = inputs.pop('labels') # removes labels from inputs and assigns to new variable\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs[0]\n",
    "        loss = custom_loss(logits, labels)\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-05-02T01:42:11.309087Z",
     "iopub.status.busy": "2024-05-02T01:42:11.308809Z",
     "iopub.status.idle": "2024-05-02T01:42:17.598104Z",
     "shell.execute_reply": "2024-05-02T01:42:17.597356Z",
     "shell.execute_reply.started": "2024-05-02T01:42:11.309064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e710f7d392143bbbebeca811992b3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfffd855b8be4cc182fc7328c6c3033d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff57887f10f45c893c679258e64d69f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b76ad655874bae89cac823166fa8a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# COLLATE: For batches\n",
    "tokenizer = AutoTokenizer.from_pretrained(TRAINING_MODEL_PATH)\n",
    "collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)\n",
    "\n",
    "# training args, args setup\n",
    "lr, epochs = 2e-5, 6\n",
    "bs, wd = 4, 0.01\n",
    "\n",
    "# model import and training \n",
    "# define model\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    TRAINING_MODEL_PATH,\n",
    "    num_labels=len(LABELS),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "class CustomCallback(TrainerCallback):\n",
    "    \n",
    "    def __init__(self, trainer) -> None:\n",
    "        super().__init__()\n",
    "        self._trainer = trainer\n",
    "    \n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if control.should_evaluate:\n",
    "            control_copy = copy.deepcopy(control)\n",
    "            self._trainer.evaluate(eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train\")\n",
    "            return control_copy\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR, \n",
    "    fp16=True,\n",
    "    learning_rate=lr,\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=bs,\n",
    "    gradient_accumulation_steps=2,\n",
    "    report_to=\"none\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    do_eval=False,\n",
    "    save_total_limit=1,\n",
    "    logging_steps=20,\n",
    "    lr_scheduler_type='cosine',\n",
    "    metric_for_best_model=\"f5\",\n",
    "    greater_is_better=True,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=wd\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model, \n",
    "    args=args, \n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_test,\n",
    "    data_collator=collator, \n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=partial(compute_metrics, all_labels=LABELS),\n",
    ")\n",
    "\n",
    "trainer.add_callback(CustomCallback(trainer)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-05-02T01:42:17.601233Z",
     "iopub.status.busy": "2024-05-02T01:42:17.600918Z",
     "iopub.status.idle": "2024-05-02T04:22:03.684017Z",
     "shell.execute_reply": "2024-05-02T04:22:03.683092Z",
     "shell.execute_reply.started": "2024-05-02T01:42:17.601194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1914' max='1914' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1914/1914 2:39:39, Epoch 5/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.338000</td>\n",
       "      <td>0.011280</td>\n",
       "      <td>0.883959</td>\n",
       "      <td>0.655696</td>\n",
       "      <td>0.872280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.017158</td>\n",
       "      <td>0.930887</td>\n",
       "      <td>0.783202</td>\n",
       "      <td>0.924185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.915529</td>\n",
       "      <td>0.869530</td>\n",
       "      <td>0.913670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.017065</td>\n",
       "      <td>0.919795</td>\n",
       "      <td>0.776098</td>\n",
       "      <td>0.913291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-05-02T04:22:03.685467Z",
     "iopub.status.busy": "2024-05-02T04:22:03.685146Z",
     "iopub.status.idle": "2024-05-02T04:22:03.696776Z",
     "shell.execute_reply": "2024-05-02T04:22:03.695970Z",
     "shell.execute_reply.started": "2024-05-02T04:22:03.685442Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train_loss': 0.017617089673876762,\n",
       "  'train_recall': 0.8376818286769799,\n",
       "  'train_precision': 0.738148524923703,\n",
       "  'train_f5': 0.8333598374414701,\n",
       "  'train_runtime': 418.7573,\n",
       "  'train_samples_per_second': 12.191,\n",
       "  'train_steps_per_second': 0.764,\n",
       "  'epoch': 1.0,\n",
       "  'step': 319},\n",
       " {'loss': 0.338,\n",
       "  'grad_norm': 9797.2568359375,\n",
       "  'learning_rate': 1.9732781109459845e-05,\n",
       "  'epoch': 1.0,\n",
       "  'step': 319},\n",
       " {'eval_loss': 0.011280144564807415,\n",
       "  'eval_recall': 0.8839590443686007,\n",
       "  'eval_precision': 0.6556962025316456,\n",
       "  'eval_f5': 0.872279792746114,\n",
       "  'eval_runtime': 139.8917,\n",
       "  'eval_samples_per_second': 12.167,\n",
       "  'eval_steps_per_second': 0.765,\n",
       "  'epoch': 1.0,\n",
       "  'step': 319},\n",
       " {'train_loss': 0.01015101931989193,\n",
       "  'train_recall': 0.9376587393211729,\n",
       "  'train_precision': 0.844809652589973,\n",
       "  'train_f5': 0.9337118197414266,\n",
       "  'train_runtime': 419.0871,\n",
       "  'train_samples_per_second': 12.181,\n",
       "  'train_steps_per_second': 0.764,\n",
       "  'epoch': 2.0,\n",
       "  'step': 639},\n",
       " {'loss': 0.0369,\n",
       "  'grad_norm': 2.4082424640655518,\n",
       "  'learning_rate': 1.6855040575851337e-05,\n",
       "  'epoch': 2.0,\n",
       "  'step': 639},\n",
       " {'eval_loss': 0.011864804662764072,\n",
       "  'eval_recall': 0.9377133105802048,\n",
       "  'eval_precision': 0.6942514213518636,\n",
       "  'eval_f5': 0.9252339474791956,\n",
       "  'eval_runtime': 139.7475,\n",
       "  'eval_samples_per_second': 12.179,\n",
       "  'eval_steps_per_second': 0.766,\n",
       "  'epoch': 2.0,\n",
       "  'step': 639},\n",
       " {'train_loss': 0.011613101698458195,\n",
       "  'train_recall': 0.9358115908566151,\n",
       "  'train_precision': 0.9002665482007997,\n",
       "  'train_f5': 0.9343926509837999,\n",
       "  'train_runtime': 417.8863,\n",
       "  'train_samples_per_second': 12.216,\n",
       "  'train_steps_per_second': 0.766,\n",
       "  'epoch': 3.0,\n",
       "  'step': 958},\n",
       " {'loss': 0.0212,\n",
       "  'grad_norm': 0.20697256922721863,\n",
       "  'learning_rate': 1.172450269888075e-05,\n",
       "  'epoch': 3.0,\n",
       "  'step': 958},\n",
       " {'eval_loss': 0.017157921567559242,\n",
       "  'eval_recall': 0.9308873720136519,\n",
       "  'eval_precision': 0.7832017229002154,\n",
       "  'eval_f5': 0.9241846675137654,\n",
       "  'eval_runtime': 139.7253,\n",
       "  'eval_samples_per_second': 12.181,\n",
       "  'eval_steps_per_second': 0.766,\n",
       "  'epoch': 3.0,\n",
       "  'step': 958},\n",
       " {'train_loss': 0.00772140733897686,\n",
       "  'train_recall': 0.9473562687601016,\n",
       "  'train_precision': 0.9354765161878705,\n",
       "  'train_f5': 0.9468937786811763,\n",
       "  'train_runtime': 418.5896,\n",
       "  'train_samples_per_second': 12.196,\n",
       "  'train_steps_per_second': 0.764,\n",
       "  'epoch': 4.0,\n",
       "  'step': 1278},\n",
       " {'loss': 0.0109,\n",
       "  'grad_norm': 0.10409563034772873,\n",
       "  'learning_rate': 6.009442236022307e-06,\n",
       "  'epoch': 4.0,\n",
       "  'step': 1278},\n",
       " {'eval_loss': 0.014831394888460636,\n",
       "  'eval_recall': 0.9291808873720137,\n",
       "  'eval_precision': 0.8691141260973663,\n",
       "  'eval_f5': 0.9267175072824273,\n",
       "  'eval_runtime': 140.0243,\n",
       "  'eval_samples_per_second': 12.155,\n",
       "  'eval_steps_per_second': 0.764,\n",
       "  'epoch': 4.0,\n",
       "  'step': 1278},\n",
       " {'train_loss': 0.004649277310818434,\n",
       "  'train_recall': 0.971830985915493,\n",
       "  'train_precision': 0.9388802141423154,\n",
       "  'train_f5': 0.9705209386473689,\n",
       "  'train_runtime': 418.0704,\n",
       "  'train_samples_per_second': 12.211,\n",
       "  'train_steps_per_second': 0.765,\n",
       "  'epoch': 5.0,\n",
       "  'step': 1597},\n",
       " {'loss': 0.0121,\n",
       "  'grad_norm': 0.06898777931928635,\n",
       "  'learning_rate': 1.6262351095448582e-06,\n",
       "  'epoch': 5.0,\n",
       "  'step': 1597},\n",
       " {'eval_loss': 0.018392756581306458,\n",
       "  'eval_recall': 0.9155290102389079,\n",
       "  'eval_precision': 0.8695299837925445,\n",
       "  'eval_f5': 0.913670007205083,\n",
       "  'eval_runtime': 139.5557,\n",
       "  'eval_samples_per_second': 12.196,\n",
       "  'eval_steps_per_second': 0.767,\n",
       "  'epoch': 5.0,\n",
       "  'step': 1597},\n",
       " {'train_loss': 0.003749795025214553,\n",
       "  'train_recall': 0.9725236665897021,\n",
       "  'train_precision': 0.9385026737967914,\n",
       "  'train_f5': 0.97116962124101,\n",
       "  'train_runtime': 418.016,\n",
       "  'train_samples_per_second': 12.212,\n",
       "  'train_steps_per_second': 0.766,\n",
       "  'epoch': 5.99,\n",
       "  'step': 1914},\n",
       " {'loss': 0.0042,\n",
       "  'grad_norm': 0.09436950087547302,\n",
       "  'learning_rate': 0.0,\n",
       "  'epoch': 5.99,\n",
       "  'step': 1914},\n",
       " {'eval_loss': 0.017064522951841354,\n",
       "  'eval_recall': 0.9197952218430034,\n",
       "  'eval_precision': 0.7760979121670266,\n",
       "  'eval_f5': 0.9132914073446512,\n",
       "  'eval_runtime': 140.0558,\n",
       "  'eval_samples_per_second': 12.152,\n",
       "  'eval_steps_per_second': 0.764,\n",
       "  'epoch': 5.99,\n",
       "  'step': 1914},\n",
       " {'train_runtime': 9585.6102,\n",
       "  'train_samples_per_second': 3.195,\n",
       "  'train_steps_per_second': 0.2,\n",
       "  'total_flos': 1.5894042365169504e+16,\n",
       "  'train_loss': 0.07055182404652659,\n",
       "  'epoch': 5.99,\n",
       "  'step': 1914}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-05-02T04:22:03.697970Z",
     "iopub.status.busy": "2024-05-02T04:22:03.697724Z",
     "iopub.status.idle": "2024-05-02T04:22:05.283501Z",
     "shell.execute_reply": "2024-05-02T04:22:05.282538Z",
     "shell.execute_reply.started": "2024-05-02T04:22:03.697948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('deberta_opttrunc/tokenizer_config.json',\n",
       " 'deberta_opttrunc/special_tokens_map.json',\n",
       " 'deberta_opttrunc/spm.model',\n",
       " 'deberta_opttrunc/added_tokens.json',\n",
       " 'deberta_opttrunc/tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"roberta_opttrunc\")\n",
    "tokenizer.save_pretrained(\"roberta_opttrunc\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    },
    {
     "sourceId": 174975549,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
