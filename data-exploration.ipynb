{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Tokenization Preprocessing\n",
    "In this notebook we: \n",
    "1. Explore the distribution of labels to answer questions such as: \n",
    "    - How many documents contain special labels\n",
    "    - How many instances of special labels do we have\n",
    "2. Tokenize the data according to both potential models and analyze based on MAX_TRAINING_LENGTH of models\n",
    "3. Standardize training and testing data for fine-tuning, including\n",
    "    - Choosing standard train/test split\n",
    "    - Partitioning the data for models that split the tokenized text into chunks\n",
    "    - Choosing standard set of files to downsample (if downsampling)\n",
    "    - Saving .csv and .txt files of all model-standardized features for easy data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and packages\n",
    "This part will need to be changed to run locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-30T23:41:55.520264Z",
     "iopub.status.busy": "2024-04-30T23:41:55.519817Z",
     "iopub.status.idle": "2024-04-30T23:41:55.879309Z",
     "shell.execute_reply": "2024-04-30T23:41:55.878398Z",
     "shell.execute_reply.started": "2024-04-30T23:41:55.520228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/pii-detection-removal-from-educational-data/sample_submission.csv\n",
      "/kaggle/input/pii-detection-removal-from-educational-data/train.json\n",
      "/kaggle/input/pii-detection-removal-from-educational-data/test.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:47:53.420936Z",
     "iopub.status.busy": "2024-04-30T23:47:53.420281Z",
     "iopub.status.idle": "2024-04-30T23:47:53.426151Z",
     "shell.execute_reply": "2024-04-30T23:47:53.425046Z",
     "shell.execute_reply.started": "2024-04-30T23:47:53.420903Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from itertools import chain\n",
    "\n",
    "from transformers import AutoTokenizer,AutoModelForTokenClassification,Trainer, TrainingArguments, AutoConfig, DataCollatorForTokenClassification, TrainerCallback\n",
    "from datasets import Dataset, features\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:42:12.947464Z",
     "iopub.status.busy": "2024-04-30T23:42:12.946026Z",
     "iopub.status.idle": "2024-04-30T23:42:15.822798Z",
     "shell.execute_reply": "2024-04-30T23:42:15.822011Z",
     "shell.execute_reply.started": "2024-04-30T23:42:12.947414Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train = json.load(open('/kaggle/input/pii-detection-removal-from-educational-data/train.json'))\n",
    "data_test = pd.read_json('/kaggle/input/pii-detection-removal-from-educational-data/test.json')\n",
    "\n",
    "df_train = pd.DataFrame(data_train)\n",
    "df_test = pd.DataFrame(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:42:15.826063Z",
     "iopub.status.busy": "2024-04-30T23:42:15.825434Z",
     "iopub.status.idle": "2024-04-30T23:42:15.831858Z",
     "shell.execute_reply": "2024-04-30T23:42:15.830677Z",
     "shell.execute_reply.started": "2024-04-30T23:42:15.826027Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training Data is 6807\n",
      "Length of Testing Data is 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of Training Data is \" + str(len(df_train)))\n",
    "print(\"Length of Testing Data is \" + str(len(df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:42:15.833404Z",
     "iopub.status.busy": "2024-04-30T23:42:15.833050Z",
     "iopub.status.idle": "2024-04-30T23:42:15.871052Z",
     "shell.execute_reply": "2024-04-30T23:42:15.870103Z",
     "shell.execute_reply.started": "2024-04-30T23:42:15.833378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n",
       "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...</td>\n",
       "      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Design Thinking for Innovation\\n\\nSindy Samaca...</td>\n",
       "      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n",
       "      <td>[True, True, True, False, False, True, False, ...</td>\n",
       "      <td>[O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>Assignment:  Visualization Reflection  Submitt...</td>\n",
       "      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document                                          full_text  \\\n",
       "0         7  Design Thinking for innovation reflexion-Avril...   \n",
       "1        10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n",
       "2        16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n",
       "3        20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n",
       "4        56  Assignment:  Visualization Reflection  Submitt...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Design, Thinking, for, innovation, reflexion,...   \n",
       "1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
       "2  [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n",
       "3  [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n",
       "4  [Assignment, :,   , Visualization,  , Reflecti...   \n",
       "\n",
       "                                 trailing_whitespace  \\\n",
       "0  [True, True, True, True, False, False, True, F...   \n",
       "1  [True, False, False, True, True, False, False,...   \n",
       "2  [True, False, False, True, True, False, False,...   \n",
       "3  [True, True, True, False, False, True, False, ...   \n",
       "4  [False, False, False, False, False, False, Fal...   \n",
       "\n",
       "                                              labels  \n",
       "0  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...  \n",
       "1  [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...  \n",
       "2  [O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...  \n",
       "3  [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:42:15.872536Z",
     "iopub.status.busy": "2024-04-30T23:42:15.872255Z",
     "iopub.status.idle": "2024-04-30T23:42:15.948465Z",
     "shell.execute_reply": "2024-04-30T23:42:15.947569Z",
     "shell.execute_reply.started": "2024-04-30T23:42:15.872513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-EMAIL', 'B-ID_NUM', 'B-NAME_STUDENT', 'B-PHONE_NUM', 'B-STREET_ADDRESS', 'B-URL_PERSONAL', 'B-USERNAME', 'I-ID_NUM', 'I-NAME_STUDENT', 'I-PHONE_NUM', 'I-STREET_ADDRESS', 'I-URL_PERSONAL', 'O']\n",
      "Length: 13\n"
     ]
    }
   ],
   "source": [
    "LABELS = sorted(list(set(chain(*df_train.labels))))\n",
    "num_labels = len(LABELS)\n",
    "\n",
    "print(LABELS)\n",
    "print('Length:', num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:42:15.950088Z",
     "iopub.status.busy": "2024-04-30T23:42:15.949769Z",
     "iopub.status.idle": "2024-04-30T23:42:15.956475Z",
     "shell.execute_reply": "2024-04-30T23:42:15.955534Z",
     "shell.execute_reply.started": "2024-04-30T23:42:15.950063Z"
    }
   },
   "outputs": [],
   "source": [
    "label2id = {l:i for i, l in enumerate(LABELS)}\n",
    "id2label = {i:l for i, l in enumerate(LABELS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:42:15.958090Z",
     "iopub.status.busy": "2024-04-30T23:42:15.957724Z",
     "iopub.status.idle": "2024-04-30T23:42:15.965549Z",
     "shell.execute_reply": "2024-04-30T23:42:15.964689Z",
     "shell.execute_reply.started": "2024-04-30T23:42:15.958066Z"
    }
   },
   "outputs": [],
   "source": [
    "# Functions to find occurences of each label\n",
    "def find_label_instances(df, label): \n",
    "    instances = 0\n",
    "    for i in range(len(df)):\n",
    "        labels = df.iloc[i].labels\n",
    "        instances += labels.count(label)\n",
    "    return instances\n",
    "    \n",
    "def find_label_number(df,label):\n",
    "    num_documents = 0\n",
    "    for i in range(len(df)):\n",
    "        labels = df.iloc[i].labels\n",
    "        if (labels.count(label) > 0): num_documents += 1\n",
    "    return num_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:42:15.967047Z",
     "iopub.status.busy": "2024-04-30T23:42:15.966764Z",
     "iopub.status.idle": "2024-04-30T23:42:28.266912Z",
     "shell.execute_reply": "2024-04-30T23:42:28.265808Z",
     "shell.execute_reply.started": "2024-04-30T23:42:15.967020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- NUMBER OF TOTAL LABEL OCCURENCES ---------- \n",
      "\n",
      "B-EMAIL              : 39\n",
      "B-ID_NUM             : 78\n",
      "B-NAME_STUDENT       : 1365\n",
      "B-PHONE_NUM          : 6\n",
      "B-STREET_ADDRESS     : 2\n",
      "B-URL_PERSONAL       : 110\n",
      "B-USERNAME           : 6\n",
      "I-ID_NUM             : 1\n",
      "I-NAME_STUDENT       : 1096\n",
      "I-PHONE_NUM          : 15\n",
      "I-STREET_ADDRESS     : 20\n",
      "I-URL_PERSONAL       : 1\n",
      "O                    : 4989794\n",
      "\n",
      "\n",
      "---------- NUMBER OF LABEL OCCURENCES ---------- \n",
      "\n",
      "B-EMAIL              : 24\n",
      "B-ID_NUM             : 33\n",
      "B-NAME_STUDENT       : 891\n",
      "B-PHONE_NUM          : 4\n",
      "B-STREET_ADDRESS     : 2\n",
      "B-URL_PERSONAL       : 72\n",
      "B-USERNAME           : 5\n",
      "I-ID_NUM             : 1\n",
      "I-NAME_STUDENT       : 814\n",
      "I-PHONE_NUM          : 3\n",
      "I-STREET_ADDRESS     : 2\n",
      "I-URL_PERSONAL       : 1\n",
      "O                    : 6807\n"
     ]
    }
   ],
   "source": [
    "tot_space = 20\n",
    "print('-' * 10, 'NUMBER OF TOTAL LABEL OCCURENCES', '-' * 10, '\\n')\n",
    "for label in LABELS: \n",
    "    num_instances = find_label_instances(df_train, label)\n",
    "    print(label, ' ' * (tot_space - len(label)) + ':', num_instances)\n",
    "    \n",
    "print('\\n')\n",
    "print('-' * 10, 'NUMBER OF LABEL OCCURENCES', '-' * 10, '\\n')\n",
    "for label in LABELS: \n",
    "    num_documents = find_label_number(df_train, label)\n",
    "    print(label, ' ' * (tot_space - len(label)) + ':', num_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenized Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:42:28.271145Z",
     "iopub.status.busy": "2024-04-30T23:42:28.270816Z",
     "iopub.status.idle": "2024-04-30T23:42:28.281022Z",
     "shell.execute_reply": "2024-04-30T23:42:28.279902Z",
     "shell.execute_reply.started": "2024-04-30T23:42:28.271119Z"
    }
   },
   "outputs": [],
   "source": [
    "def reconstruct(batch): \n",
    "    text = []\n",
    "    labels = []\n",
    "    \n",
    "    for t, l, ws in zip(\n",
    "        batch[\"tokens\"], batch[\"labels\"], batch[\"trailing_whitespace\"]):\n",
    "            \n",
    "            text.append(t)\n",
    "            labels.extend([l]*len(t))\n",
    "            \n",
    "            if ws: \n",
    "                text.append(\" \")\n",
    "                labels.append(\"O\")\n",
    "                \n",
    "    return \"\".join(text),np.array(labels)\n",
    "\n",
    "def tokenize(batch, tokenizer):\n",
    "    \n",
    "    text,labels = reconstruct(batch)\n",
    "    \n",
    "    # Tokenize with pre-trained tokenizer\n",
    "    #tokenized = tokenizer(text, return_offsets_mapping=True, max_length=TRAINING_MAX_LENGTH)\n",
    "    tokenized = tokenizer(text, return_offsets_mapping=True)\n",
    "    \n",
    "    # Create labels for each token \n",
    "    token_labels = []\n",
    "    \n",
    "    for start_idx, end_idx in tokenized.offset_mapping:\n",
    "        # CLS token\n",
    "        if start_idx == 0 and end_idx == 0:\n",
    "            token_labels.append(label2id[\"O\"])\n",
    "            continue\n",
    "\n",
    "        # case when token starts with whitespace\n",
    "        if text[start_idx].isspace():\n",
    "            start_idx += 1\n",
    "\n",
    "        token_labels.append(label2id[labels[start_idx]])\n",
    "\n",
    "    length = len(tokenized.input_ids)\n",
    "\n",
    "    return tokenized.input_ids, tokenized.attention_mask, tokenized.offset_mapping, token_labels, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:42:28.283166Z",
     "iopub.status.busy": "2024-04-30T23:42:28.282533Z",
     "iopub.status.idle": "2024-04-30T23:43:05.107928Z",
     "shell.execute_reply": "2024-04-30T23:43:05.107111Z",
     "shell.execute_reply.started": "2024-04-30T23:42:28.283133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1798df99edf747c5b7fa2a6920758ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcacb773e42e4372b1da038b132f95a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993231d1855146e8869f9e6ddd17ced6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b7a08bda78245d18e247030298a6565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41257e123fe94625bd4d7ec21462a8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (835 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Model (Roberta) Settings from Hugging Face: Path, Length, Output Directory\n",
    "TRAINING_MODEL_PATH = \"FacebookAI/roberta-base\"\n",
    "TRAINING_MAX_LENGTH = 512\n",
    "tokenizer = AutoTokenizer.from_pretrained(TRAINING_MODEL_PATH)\n",
    "df_train[['roberta_input_ids', 'roberta_attention_mask', 'roberta_offset_mapping', 'roberta_token_labels', 'roberta_length']] = df_train.apply(lambda row: tokenize(row, tokenizer), axis='columns', result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:43:05.109253Z",
     "iopub.status.busy": "2024-04-30T23:43:05.108998Z",
     "iopub.status.idle": "2024-04-30T23:43:40.805093Z",
     "shell.execute_reply": "2024-04-30T23:43:40.804249Z",
     "shell.execute_reply.started": "2024-04-30T23:43:05.109231Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b245dbf5a3742dfae786a9a5b5e58a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858685b765094fa2b7fa8f4ea8fcd6d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af7cc17eaee4874b2b752e725e9fa3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Model (Deberta) Settings from Hugging Face: Path, Length, Output Directory\n",
    "TRAINING_MODEL_PATH = \"microsoft/deberta-v3-base\"\n",
    "TRAINING_MAX_LENGTH = 1024\n",
    "tokenizer = AutoTokenizer.from_pretrained(TRAINING_MODEL_PATH)\n",
    "df_train[['deberta_input_ids', 'deberta_attention_mask', 'deberta_offset_mapping', 'deberta_token_labels', 'deberta_length']] = df_train.apply(lambda row: tokenize(row, tokenizer), axis='columns', result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:43:40.806727Z",
     "iopub.status.busy": "2024-04-30T23:43:40.806359Z",
     "iopub.status.idle": "2024-04-30T23:43:40.821762Z",
     "shell.execute_reply": "2024-04-30T23:43:40.820721Z",
     "shell.execute_reply.started": "2024-04-30T23:43:40.806694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- RoBerta Stats ---------- \n",
      "\n",
      "Length 512        : 5495\n",
      "Length 1024       : 1372\n",
      "Length 2048       : 87\n",
      "\n",
      "\n",
      "---------- DeBerta Stats ---------- \n",
      "\n",
      "Length 512        : 4907\n",
      "Length 1024       : 762\n",
      "Length 2048       : 14\n"
     ]
    }
   ],
   "source": [
    "# Determine What percentage of training data is over TRAINING_MAX_LENGTH for each model\n",
    "lengths = [512, 1024, 2048]\n",
    "tot_space = 10\n",
    "\n",
    "print('-' * 10, 'RoBerta Stats', '-' * 10, '\\n')\n",
    "roberta_lengths = df_train['roberta_length']\n",
    "for l in lengths: \n",
    "    count = sum(roberta_lengths > l)\n",
    "    str_l = str(l)\n",
    "    print('Length', l, ' ' * (tot_space - len(str_l)) + ':', count)\n",
    "    \n",
    "print('\\n')\n",
    "print('-' * 10, 'DeBerta Stats', '-' * 10, '\\n')\n",
    "deberta_lengths = df_train['deberta_length']\n",
    "for l in lengths: \n",
    "    count = sum(deberta_lengths > l)\n",
    "    str_l = str(l)\n",
    "    print('Length', l, ' ' * (tot_space - len(str_l)) + ':', count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documents for downsampling\n",
    "If downsampling, we choose to eliminate a (standardized) random half of all documents with no PII labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:43:40.823309Z",
     "iopub.status.busy": "2024-04-30T23:43:40.822971Z",
     "iopub.status.idle": "2024-04-30T23:43:40.832223Z",
     "shell.execute_reply": "2024-04-30T23:43:40.831146Z",
     "shell.execute_reply.started": "2024-04-30T23:43:40.823275Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find documents with no \"special\" labels\n",
    "def find_documents(df): \n",
    "    documents = []\n",
    "    for index, row in df.iterrows(): \n",
    "        labels = row.labels\n",
    "        if (labels.count(\"O\") == len(labels)): \n",
    "            documents.append(row.document)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-05-01T00:30:07.738661Z",
     "iopub.status.busy": "2024-05-01T00:30:07.737627Z",
     "iopub.status.idle": "2024-05-01T00:30:08.148407Z",
     "shell.execute_reply": "2024-05-01T00:30:08.146918Z",
     "shell.execute_reply.started": "2024-05-01T00:30:07.738615Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'find_documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bad_documents \u001b[38;5;241m=\u001b[39m \u001b[43mfind_documents\u001b[49m(df_train)\n\u001b[1;32m      2\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(bad_documents)\n\u001b[1;32m      3\u001b[0m to_cut \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoices(bad_documents, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(n \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'find_documents' is not defined"
     ]
    }
   ],
   "source": [
    "bad_documents = find_documents(df_train)\n",
    "n = len(bad_documents)\n",
    "to_cut = random.choices(bad_documents, k=int(n / 2))\n",
    "print(len(to_cut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:51:24.200783Z",
     "iopub.status.busy": "2024-04-30T23:51:24.200020Z",
     "iopub.status.idle": "2024-04-30T23:51:24.207699Z",
     "shell.execute_reply": "2024-04-30T23:51:24.206654Z",
     "shell.execute_reply.started": "2024-04-30T23:51:24.200751Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('docs2cut.txt', 'w') as file:\n",
    "    for number in to_cut:\n",
    "        file.write(f\"{number}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardized Train/Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:43:41.332710Z",
     "iopub.status.busy": "2024-04-30T23:43:41.332402Z",
     "iopub.status.idle": "2024-04-30T23:43:42.202317Z",
     "shell.execute_reply": "2024-04-30T23:43:42.201345Z",
     "shell.execute_reply.started": "2024-04-30T23:43:41.332684Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add columns indicating which labels are present\n",
    "df_train['B-EMAIL'] = df_train.apply(lambda row: 'B-EMAIL' in set(row.labels), axis='columns', result_type='expand')\n",
    "df_train['B-ID_NUM'] = df_train.apply(lambda row: 'B-ID_NUM' in set(row.labels), axis='columns', result_type='expand')\n",
    "df_train['B-NAME_STUDENT'] = df_train.apply(lambda row: 'B-NAME_STUDENT' in set(row.labels), axis='columns', result_type='expand')\n",
    "df_train['B-URL_PERSONAL'] = df_train.apply(lambda row: 'B-URL_PERSONAL' in set(row.labels), axis='columns', result_type='expand')\n",
    "df_train['I-NAME_STUDENT'] = df_train.apply(lambda row: 'I-NAME_STUDENT' in set(row.labels), axis='columns', result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:43:42.203841Z",
     "iopub.status.busy": "2024-04-30T23:43:42.203548Z",
     "iopub.status.idle": "2024-04-30T23:43:42.306114Z",
     "shell.execute_reply": "2024-04-30T23:43:42.305341Z",
     "shell.execute_reply.started": "2024-04-30T23:43:42.203816Z"
    }
   },
   "outputs": [],
   "source": [
    "# we can't stratify including B-EMAIL - just how the data works out, \n",
    "# there are too few data points with email so that it won't work \n",
    "train, test = train_test_split(df_train, \n",
    "                 shuffle=True,\n",
    "                 random_state=42,\n",
    "                 stratify=df_train[['B-URL_PERSONAL', \n",
    "                                           'B-NAME_STUDENT',\n",
    "                                           'I-NAME_STUDENT',\n",
    "                                           'B-ID_NUM'\n",
    "                                          ]],\n",
    "                 test_size=0.25\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:43:42.308139Z",
     "iopub.status.busy": "2024-04-30T23:43:42.307389Z",
     "iopub.status.idle": "2024-04-30T23:43:55.576765Z",
     "shell.execute_reply": "2024-04-30T23:43:55.575575Z",
     "shell.execute_reply.started": "2024-04-30T23:43:42.308102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- NUMBER OF TOTAL LABEL OCCURENCES: TRAINING ---------- \n",
      "\n",
      "B-EMAIL              : 30\n",
      "B-ID_NUM             : 59\n",
      "B-NAME_STUDENT       : 1032\n",
      "B-PHONE_NUM          : 6\n",
      "B-STREET_ADDRESS     : 2\n",
      "B-URL_PERSONAL       : 89\n",
      "B-USERNAME           : 3\n",
      "I-ID_NUM             : 0\n",
      "I-NAME_STUDENT       : 807\n",
      "I-PHONE_NUM          : 15\n",
      "I-STREET_ADDRESS     : 20\n",
      "I-URL_PERSONAL       : 1\n",
      "O                    : 3734808\n",
      "\n",
      "\n",
      "---------- NUMBER OF LABEL OCCURENCES: TRAINING ---------- \n",
      "\n",
      "B-EMAIL              : 19\n",
      "B-ID_NUM             : 25\n",
      "B-NAME_STUDENT       : 667\n",
      "B-PHONE_NUM          : 4\n",
      "B-STREET_ADDRESS     : 2\n",
      "B-URL_PERSONAL       : 54\n",
      "B-USERNAME           : 3\n",
      "I-ID_NUM             : 0\n",
      "I-NAME_STUDENT       : 610\n",
      "I-PHONE_NUM          : 3\n",
      "I-STREET_ADDRESS     : 2\n",
      "I-URL_PERSONAL       : 1\n",
      "O                    : 5105\n"
     ]
    }
   ],
   "source": [
    "tot_space = 20\n",
    "print('-' * 10, 'NUMBER OF TOTAL LABEL OCCURENCES: TRAINING', '-' * 10, '\\n')\n",
    "for label in LABELS: \n",
    "    num_instances = find_label_instances(train, label)\n",
    "    print(label, ' ' * (tot_space - len(label)) + ':', num_instances)\n",
    "    \n",
    "print('\\n')\n",
    "print('-' * 10, 'NUMBER OF LABEL OCCURENCES: TRAINING', '-' * 10, '\\n')\n",
    "for label in LABELS: \n",
    "    num_documents = find_label_number(train, label)\n",
    "    print(label, ' ' * (tot_space - len(label)) + ':', num_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:43:55.578928Z",
     "iopub.status.busy": "2024-04-30T23:43:55.578550Z",
     "iopub.status.idle": "2024-04-30T23:43:59.959472Z",
     "shell.execute_reply": "2024-04-30T23:43:59.958510Z",
     "shell.execute_reply.started": "2024-04-30T23:43:55.578893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- NUMBER OF TOTAL LABEL OCCURENCES: TESTING ---------- \n",
      "\n",
      "B-EMAIL              : 9\n",
      "B-ID_NUM             : 19\n",
      "B-NAME_STUDENT       : 333\n",
      "B-PHONE_NUM          : 0\n",
      "B-STREET_ADDRESS     : 0\n",
      "B-URL_PERSONAL       : 21\n",
      "B-USERNAME           : 3\n",
      "I-ID_NUM             : 1\n",
      "I-NAME_STUDENT       : 289\n",
      "I-PHONE_NUM          : 0\n",
      "I-STREET_ADDRESS     : 0\n",
      "I-URL_PERSONAL       : 0\n",
      "O                    : 1254986\n",
      "\n",
      "\n",
      "---------- NUMBER OF LABEL OCCURENCES: TESTING ---------- \n",
      "\n",
      "B-EMAIL              : 5\n",
      "B-ID_NUM             : 8\n",
      "B-NAME_STUDENT       : 224\n",
      "B-PHONE_NUM          : 0\n",
      "B-STREET_ADDRESS     : 0\n",
      "B-URL_PERSONAL       : 18\n",
      "B-USERNAME           : 2\n",
      "I-ID_NUM             : 1\n",
      "I-NAME_STUDENT       : 204\n",
      "I-PHONE_NUM          : 0\n",
      "I-STREET_ADDRESS     : 0\n",
      "I-URL_PERSONAL       : 0\n",
      "O                    : 1702\n"
     ]
    }
   ],
   "source": [
    "tot_space = 20\n",
    "print('-' * 10, 'NUMBER OF TOTAL LABEL OCCURENCES: TESTING', '-' * 10, '\\n')\n",
    "for label in LABELS: \n",
    "    num_instances = find_label_instances(test, label)\n",
    "    print(label, ' ' * (tot_space - len(label)) + ':', num_instances)\n",
    "    \n",
    "print('\\n')\n",
    "print('-' * 10, 'NUMBER OF LABEL OCCURENCES: TESTING', '-' * 10, '\\n')\n",
    "for label in LABELS: \n",
    "    num_documents = find_label_number(test, label)\n",
    "    print(label, ' ' * (tot_space - len(label)) + ':', num_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:43:59.960920Z",
     "iopub.status.busy": "2024-04-30T23:43:59.960648Z",
     "iopub.status.idle": "2024-04-30T23:44:23.528846Z",
     "shell.execute_reply": "2024-04-30T23:44:23.527752Z",
     "shell.execute_reply.started": "2024-04-30T23:43:59.960897Z"
    }
   },
   "outputs": [],
   "source": [
    "train.to_csv(\"train.csv\", index=False)\n",
    "test.to_csv(\"test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:44:23.531698Z",
     "iopub.status.busy": "2024-04-30T23:44:23.531303Z",
     "iopub.status.idle": "2024-04-30T23:44:23.539210Z",
     "shell.execute_reply": "2024-04-30T23:44:23.537942Z",
     "shell.execute_reply.started": "2024-04-30T23:44:23.531664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['document', 'full_text', 'tokens', 'trailing_whitespace', 'labels',\n",
       "       'roberta_input_ids', 'roberta_attention_mask', 'roberta_offset_mapping',\n",
       "       'roberta_token_labels', 'roberta_length', 'deberta_input_ids',\n",
       "       'deberta_attention_mask', 'deberta_offset_mapping',\n",
       "       'deberta_token_labels', 'deberta_length', 'B-EMAIL', 'B-ID_NUM',\n",
       "       'B-NAME_STUDENT', 'B-URL_PERSONAL', 'I-NAME_STUDENT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partitioning Data for each base language model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:44:23.541018Z",
     "iopub.status.busy": "2024-04-30T23:44:23.540622Z",
     "iopub.status.idle": "2024-04-30T23:44:23.555430Z",
     "shell.execute_reply": "2024-04-30T23:44:23.554269Z",
     "shell.execute_reply.started": "2024-04-30T23:44:23.540962Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_files(df, MAX_LENGTH): \n",
    "    df_split = pd.DataFrame(columns = ['document', 'full_text', 'tokens', 'trailing_whitespace', 'provided_labels', 'input_ids', 'attention_mask', 'offset_mapping', 'labels'])\n",
    "\n",
    "    for index, row in df.iterrows(): \n",
    "        document = df.loc[index].document\n",
    "        full_text = df.loc[index].full_text\n",
    "        tokens = df.loc[index].tokens\n",
    "        trailing_whitespace = df.loc[index].trailing_whitespace\n",
    "        provided_labels = df.loc[index].provided_labels\n",
    "        input_ids = df.loc[index].input_ids\n",
    "        attention_mask = df.loc[index].attention_mask\n",
    "        offset_mapping = df.loc[index].offset_mapping\n",
    "        labels = df.loc[index].labels\n",
    "        length = df.loc[index].length\n",
    "        num_rows = -(length // -MAX_LENGTH)       \n",
    "        for i in range(num_rows): \n",
    "            new_input_ids = input_ids[i*MAX_LENGTH: (i + 1)* MAX_LENGTH]\n",
    "            new_attention_mask = attention_mask[i*MAX_LENGTH: (i + 1)* MAX_LENGTH]\n",
    "            new_offset_mapping = offset_mapping[i*MAX_LENGTH: (i + 1)* MAX_LENGTH]\n",
    "            new_labels = labels[i*MAX_LENGTH: (i + 1)* MAX_LENGTH]\n",
    "            df_split = df_split._append({'document': document, 'full_text': full_text, 'tokens': tokens, 'trailing_whitespace': trailing_whitespace, 'provided_labels': provided_labels, 'input_ids': new_input_ids, 'attention_mask': new_attention_mask, 'offset_mapping': new_offset_mapping, 'labels': new_labels}, ignore_index=True)\n",
    "    \n",
    "    return df_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR ROBERTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:44:23.559644Z",
     "iopub.status.busy": "2024-04-30T23:44:23.559357Z",
     "iopub.status.idle": "2024-04-30T23:44:23.587447Z",
     "shell.execute_reply": "2024-04-30T23:44:23.586431Z",
     "shell.execute_reply.started": "2024-04-30T23:44:23.559621Z"
    }
   },
   "outputs": [],
   "source": [
    "roberta_train_train = pd.DataFrame(columns = ['document', 'full_text', 'tokens', 'trailing_whitespace', 'provided_labels', 'input_ids', 'attention_mask', 'offset_mapping', 'labels', 'length'])\n",
    "roberta_train_train[['document', 'full_text', 'tokens', 'trailing_whitespace', \n",
    "                     'provided_labels', 'input_ids', 'attention_mask', \n",
    "                     'offset_mapping', 'labels', 'length']]= train[['document', 'full_text', 'tokens', 'trailing_whitespace', 'labels', 'roberta_input_ids', 'roberta_attention_mask', 'roberta_offset_mapping', 'roberta_token_labels', 'roberta_length']]\n",
    "\n",
    "roberta_test_test = pd.DataFrame(columns = ['document', 'full_text', 'tokens', 'trailing_whitespace', 'provided_labels', 'input_ids', 'attention_mask', 'offset_mapping', 'labels', 'length'])\n",
    "roberta_test_test[['document', 'full_text', 'tokens', 'trailing_whitespace', \n",
    "                     'provided_labels', 'input_ids', 'attention_mask', \n",
    "                     'offset_mapping', 'labels', 'length']]= test[['document', 'full_text', 'tokens', 'trailing_whitespace', 'labels', 'roberta_input_ids', 'roberta_attention_mask', 'roberta_offset_mapping', 'roberta_token_labels', 'roberta_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:44:23.589379Z",
     "iopub.status.busy": "2024-04-30T23:44:23.589075Z",
     "iopub.status.idle": "2024-04-30T23:44:56.450544Z",
     "shell.execute_reply": "2024-04-30T23:44:56.449520Z",
     "shell.execute_reply.started": "2024-04-30T23:44:23.589353Z"
    }
   },
   "outputs": [],
   "source": [
    "roberta_train = split_files(roberta_train_train, 512)\n",
    "roberta_test = split_files(roberta_test_test, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:44:56.452046Z",
     "iopub.status.busy": "2024-04-30T23:44:56.451732Z",
     "iopub.status.idle": "2024-04-30T23:44:58.021079Z",
     "shell.execute_reply": "2024-04-30T23:44:58.020174Z",
     "shell.execute_reply.started": "2024-04-30T23:44:56.452016Z"
    }
   },
   "outputs": [],
   "source": [
    "roberta_train['B-EMAIL'] = roberta_train.apply(lambda row: label2id['B-EMAIL'] in set(row.labels), axis='columns', result_type='expand')\n",
    "roberta_train['B-ID_NUM'] = roberta_train.apply(lambda row: label2id['B-ID_NUM'] in set(row.labels), axis='columns', result_type='expand')\n",
    "roberta_train['B-NAME_STUDENT'] = roberta_train.apply(lambda row: label2id['B-NAME_STUDENT'] in set(row.labels), axis='columns', result_type='expand')\n",
    "roberta_train['B-URL_PERSONAL'] = roberta_train.apply(lambda row: label2id['B-URL_PERSONAL'] in set(row.labels), axis='columns', result_type='expand')\n",
    "roberta_train['I-NAME_STUDENT'] = roberta_train.apply(lambda row: label2id['I-NAME_STUDENT'] in set(row.labels), axis='columns', result_type='expand')\n",
    "\n",
    "\n",
    "roberta_test['B-EMAIL'] = roberta_test.apply(lambda row: label2id['B-EMAIL'] in set(row.labels), axis='columns', result_type='expand')\n",
    "roberta_test['B-ID_NUM'] = roberta_test.apply(lambda row: label2id['B-ID_NUM'] in set(row.labels), axis='columns', result_type='expand')\n",
    "roberta_test['B-NAME_STUDENT'] = roberta_test.apply(lambda row: label2id['B-NAME_STUDENT'] in set(row.labels), axis='columns', result_type='expand')\n",
    "roberta_test['B-URL_PERSONAL'] = roberta_test.apply(lambda row: label2id['B-URL_PERSONAL'] in set(row.labels), axis='columns', result_type='expand')\n",
    "roberta_test['I-NAME_STUDENT'] = roberta_test.apply(lambda row: label2id['I-NAME_STUDENT'] in set(row.labels), axis='columns', result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:44:58.022925Z",
     "iopub.status.busy": "2024-04-30T23:44:58.022654Z",
     "iopub.status.idle": "2024-04-30T23:45:21.768530Z",
     "shell.execute_reply": "2024-04-30T23:45:21.767495Z",
     "shell.execute_reply.started": "2024-04-30T23:44:58.022900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- NUMBER OF TOTAL LABEL OCCURENCES: TRAINING ---------- \n",
      "\n",
      "B-EMAIL              : 257\n",
      "B-ID_NUM             : 369\n",
      "B-NAME_STUDENT       : 2380\n",
      "B-PHONE_NUM          : 13\n",
      "B-STREET_ADDRESS     : 5\n",
      "B-URL_PERSONAL       : 1462\n",
      "B-USERNAME           : 12\n",
      "I-ID_NUM             : 0\n",
      "I-NAME_STUDENT       : 1419\n",
      "I-PHONE_NUM          : 46\n",
      "I-STREET_ADDRESS     : 33\n",
      "I-URL_PERSONAL       : 8\n",
      "O                    : 4100929\n",
      "\n",
      "\n",
      "---------- NUMBER OF LABEL OCCURENCES: TRAINING ---------- \n",
      "\n",
      "B-EMAIL              : 23\n",
      "B-ID_NUM             : 30\n",
      "B-NAME_STUDENT       : 780\n",
      "B-PHONE_NUM          : 5\n",
      "B-STREET_ADDRESS     : 2\n",
      "B-URL_PERSONAL       : 69\n",
      "B-USERNAME           : 3\n",
      "I-ID_NUM             : 0\n",
      "I-NAME_STUDENT       : 709\n",
      "I-PHONE_NUM          : 4\n",
      "I-STREET_ADDRESS     : 2\n",
      "I-URL_PERSONAL       : 1\n",
      "O                    : 10603\n"
     ]
    }
   ],
   "source": [
    "tot_space = 20\n",
    "print('-' * 10, 'NUMBER OF TOTAL LABEL OCCURENCES: TRAINING', '-' * 10, '\\n')\n",
    "for label in LABELS: \n",
    "    num_instances = find_label_instances(roberta_train, label2id[label])\n",
    "    print(label, ' ' * (tot_space - len(label)) + ':', num_instances)\n",
    "    \n",
    "print('\\n')\n",
    "print('-' * 10, 'NUMBER OF LABEL OCCURENCES: TRAINING', '-' * 10, '\\n')\n",
    "for label in LABELS: \n",
    "    num_documents = find_label_number(roberta_train, label2id[label])\n",
    "    print(label, ' ' * (tot_space - len(label)) + ':', num_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:45:21.770459Z",
     "iopub.status.busy": "2024-04-30T23:45:21.770069Z",
     "iopub.status.idle": "2024-04-30T23:45:29.723055Z",
     "shell.execute_reply": "2024-04-30T23:45:29.722046Z",
     "shell.execute_reply.started": "2024-04-30T23:45:21.770422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- NUMBER OF TOTAL LABEL OCCURENCES: TESTING ---------- \n",
      "\n",
      "B-EMAIL              : 66\n",
      "B-ID_NUM             : 116\n",
      "B-NAME_STUDENT       : 807\n",
      "B-PHONE_NUM          : 0\n",
      "B-STREET_ADDRESS     : 0\n",
      "B-URL_PERSONAL       : 367\n",
      "B-USERNAME           : 11\n",
      "I-ID_NUM             : 4\n",
      "I-NAME_STUDENT       : 501\n",
      "I-PHONE_NUM          : 0\n",
      "I-STREET_ADDRESS     : 0\n",
      "I-URL_PERSONAL       : 0\n",
      "O                    : 1370299\n",
      "\n",
      "\n",
      "---------- NUMBER OF LABEL OCCURENCES: TESTING ---------- \n",
      "\n",
      "B-EMAIL              : 8\n",
      "B-ID_NUM             : 10\n",
      "B-NAME_STUDENT       : 266\n",
      "B-PHONE_NUM          : 0\n",
      "B-STREET_ADDRESS     : 0\n",
      "B-URL_PERSONAL       : 18\n",
      "B-USERNAME           : 3\n",
      "I-ID_NUM             : 1\n",
      "I-NAME_STUDENT       : 243\n",
      "I-PHONE_NUM          : 0\n",
      "I-STREET_ADDRESS     : 0\n",
      "I-URL_PERSONAL       : 0\n",
      "O                    : 3529\n"
     ]
    }
   ],
   "source": [
    "tot_space = 20\n",
    "print('-' * 10, 'NUMBER OF TOTAL LABEL OCCURENCES: TESTING', '-' * 10, '\\n')\n",
    "for label in LABELS: \n",
    "    num_instances = find_label_instances(roberta_test, label2id[label])\n",
    "    print(label, ' ' * (tot_space - len(label)) + ':', num_instances)\n",
    "    \n",
    "print('\\n')\n",
    "print('-' * 10, 'NUMBER OF LABEL OCCURENCES: TESTING', '-' * 10, '\\n')\n",
    "for label in LABELS: \n",
    "    num_documents = find_label_number(roberta_test, label2id[label])\n",
    "    print(label, ' ' * (tot_space - len(label)) + ':', num_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T23:50:01.989976Z",
     "iopub.status.busy": "2024-04-29T23:50:01.989039Z",
     "iopub.status.idle": "2024-04-29T23:50:01.995953Z",
     "shell.execute_reply": "2024-04-29T23:50:01.994710Z",
     "shell.execute_reply.started": "2024-04-29T23:50:01.989938Z"
    }
   },
   "source": [
    "FOR DEBERTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:45:29.729394Z",
     "iopub.status.busy": "2024-04-30T23:45:29.729093Z",
     "iopub.status.idle": "2024-04-30T23:45:29.755430Z",
     "shell.execute_reply": "2024-04-30T23:45:29.754537Z",
     "shell.execute_reply.started": "2024-04-30T23:45:29.729367Z"
    }
   },
   "outputs": [],
   "source": [
    "deberta_train_train = pd.DataFrame(columns = ['document', 'full_text', 'tokens', 'trailing_whitespace', 'provided_labels', 'input_ids', 'attention_mask', 'offset_mapping', 'labels', 'length'])\n",
    "deberta_train_train[['document', 'full_text', 'tokens', 'trailing_whitespace', \n",
    "                     'provided_labels', 'input_ids', 'attention_mask', \n",
    "                     'offset_mapping', 'labels', 'length']]= train[['document', 'full_text', 'tokens', 'trailing_whitespace', 'labels', 'deberta_input_ids', 'deberta_attention_mask', 'deberta_offset_mapping', 'deberta_token_labels', 'deberta_length']]\n",
    "\n",
    "deberta_test_test = pd.DataFrame(columns = ['document', 'full_text', 'tokens', 'trailing_whitespace', 'provided_labels', 'input_ids', 'attention_mask', 'offset_mapping', 'labels', 'length'])\n",
    "deberta_test_test[['document', 'full_text', 'tokens', 'trailing_whitespace', \n",
    "                     'provided_labels', 'input_ids', 'attention_mask', \n",
    "                     'offset_mapping', 'labels', 'length']]= test[['document', 'full_text', 'tokens', 'trailing_whitespace', 'labels', 'deberta_input_ids', 'deberta_attention_mask', 'deberta_offset_mapping', 'deberta_token_labels', 'deberta_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:45:29.757070Z",
     "iopub.status.busy": "2024-04-30T23:45:29.756633Z",
     "iopub.status.idle": "2024-04-30T23:45:49.189501Z",
     "shell.execute_reply": "2024-04-30T23:45:49.188671Z",
     "shell.execute_reply.started": "2024-04-30T23:45:29.757002Z"
    }
   },
   "outputs": [],
   "source": [
    "deberta_train = split_files(deberta_train_train, 1024)\n",
    "deberta_test = split_files(deberta_test_test, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:45:49.191151Z",
     "iopub.status.busy": "2024-04-30T23:45:49.190771Z",
     "iopub.status.idle": "2024-04-30T23:45:50.075696Z",
     "shell.execute_reply": "2024-04-30T23:45:50.074747Z",
     "shell.execute_reply.started": "2024-04-30T23:45:49.191117Z"
    }
   },
   "outputs": [],
   "source": [
    "deberta_train['B-EMAIL'] = deberta_train.apply(lambda row: label2id['B-EMAIL'] in set(row.labels), axis='columns', result_type='expand')\n",
    "deberta_train['B-ID_NUM'] = deberta_train.apply(lambda row: label2id['B-ID_NUM'] in set(row.labels), axis='columns', result_type='expand')\n",
    "deberta_train['B-NAME_STUDENT'] = deberta_train.apply(lambda row: label2id['B-NAME_STUDENT'] in set(row.labels), axis='columns', result_type='expand')\n",
    "deberta_train['B-URL_PERSONAL'] = deberta_train.apply(lambda row: label2id['B-URL_PERSONAL'] in set(row.labels), axis='columns', result_type='expand')\n",
    "deberta_train['I-NAME_STUDENT'] = deberta_train.apply(lambda row: label2id['I-NAME_STUDENT'] in set(row.labels), axis='columns', result_type='expand')\n",
    "\n",
    "\n",
    "deberta_test['B-EMAIL'] = deberta_test.apply(lambda row: label2id['B-EMAIL'] in set(row.labels), axis='columns', result_type='expand')\n",
    "deberta_test['B-ID_NUM'] = deberta_test.apply(lambda row: label2id['B-ID_NUM'] in set(row.labels), axis='columns', result_type='expand')\n",
    "deberta_test['B-NAME_STUDENT'] = deberta_test.apply(lambda row: label2id['B-NAME_STUDENT'] in set(row.labels), axis='columns', result_type='expand')\n",
    "deberta_test['B-URL_PERSONAL'] = deberta_test.apply(lambda row: label2id['B-URL_PERSONAL'] in set(row.labels), axis='columns', result_type='expand')\n",
    "deberta_test['I-NAME_STUDENT'] = deberta_test.apply(lambda row: label2id['I-NAME_STUDENT'] in set(row.labels), axis='columns', result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:45:50.077316Z",
     "iopub.status.busy": "2024-04-30T23:45:50.076959Z",
     "iopub.status.idle": "2024-04-30T23:46:03.523838Z",
     "shell.execute_reply": "2024-04-30T23:46:03.522566Z",
     "shell.execute_reply.started": "2024-04-30T23:45:50.077285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- NUMBER OF TOTAL LABEL OCCURENCES: TRAINING ---------- \n",
      "\n",
      "B-EMAIL              : 209\n",
      "B-ID_NUM             : 287\n",
      "B-NAME_STUDENT       : 1317\n",
      "B-PHONE_NUM          : 11\n",
      "B-STREET_ADDRESS     : 2\n",
      "B-URL_PERSONAL       : 1528\n",
      "B-USERNAME           : 11\n",
      "I-ID_NUM             : 0\n",
      "I-NAME_STUDENT       : 1071\n",
      "I-PHONE_NUM          : 39\n",
      "I-STREET_ADDRESS     : 22\n",
      "I-URL_PERSONAL       : 7\n",
      "O                    : 3521120\n",
      "\n",
      "\n",
      "---------- NUMBER OF LABEL OCCURENCES: TRAINING ---------- \n",
      "\n",
      "B-EMAIL              : 19\n",
      "B-ID_NUM             : 25\n",
      "B-NAME_STUDENT       : 682\n",
      "B-PHONE_NUM          : 4\n",
      "B-STREET_ADDRESS     : 2\n",
      "B-URL_PERSONAL       : 58\n",
      "B-USERNAME           : 3\n",
      "I-ID_NUM             : 0\n",
      "I-NAME_STUDENT       : 624\n",
      "I-PHONE_NUM          : 3\n",
      "I-STREET_ADDRESS     : 2\n",
      "I-URL_PERSONAL       : 1\n",
      "O                    : 5695\n"
     ]
    }
   ],
   "source": [
    "tot_space = 20\n",
    "print('-' * 10, 'NUMBER OF TOTAL LABEL OCCURENCES: TRAINING', '-' * 10, '\\n')\n",
    "for label in LABELS: \n",
    "    num_instances = find_label_instances(deberta_train, label2id[label])\n",
    "    print(label, ' ' * (tot_space - len(label)) + ':', num_instances)\n",
    "    \n",
    "print('\\n')\n",
    "print('-' * 10, 'NUMBER OF LABEL OCCURENCES: TRAINING', '-' * 10, '\\n')\n",
    "for label in LABELS: \n",
    "    num_documents = find_label_number(deberta_train, label2id[label])\n",
    "    print(label, ' ' * (tot_space - len(label)) + ':', num_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:46:03.525565Z",
     "iopub.status.busy": "2024-04-30T23:46:03.525252Z",
     "iopub.status.idle": "2024-04-30T23:46:07.942367Z",
     "shell.execute_reply": "2024-04-30T23:46:07.941397Z",
     "shell.execute_reply.started": "2024-04-30T23:46:03.525538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- NUMBER OF TOTAL LABEL OCCURENCES: TESTING ---------- \n",
      "\n",
      "B-EMAIL              : 54\n",
      "B-ID_NUM             : 85\n",
      "B-NAME_STUDENT       : 437\n",
      "B-PHONE_NUM          : 0\n",
      "B-STREET_ADDRESS     : 0\n",
      "B-URL_PERSONAL       : 383\n",
      "B-USERNAME           : 10\n",
      "I-ID_NUM             : 3\n",
      "I-NAME_STUDENT       : 393\n",
      "I-PHONE_NUM          : 0\n",
      "I-STREET_ADDRESS     : 0\n",
      "I-URL_PERSONAL       : 0\n",
      "O                    : 1183923\n",
      "\n",
      "\n",
      "---------- NUMBER OF LABEL OCCURENCES: TESTING ---------- \n",
      "\n",
      "B-EMAIL              : 5\n",
      "B-ID_NUM             : 8\n",
      "B-NAME_STUDENT       : 229\n",
      "B-PHONE_NUM          : 0\n",
      "B-STREET_ADDRESS     : 0\n",
      "B-URL_PERSONAL       : 19\n",
      "B-USERNAME           : 2\n",
      "I-ID_NUM             : 1\n",
      "I-NAME_STUDENT       : 208\n",
      "I-PHONE_NUM          : 0\n",
      "I-STREET_ADDRESS     : 0\n",
      "I-URL_PERSONAL       : 0\n",
      "O                    : 1889\n"
     ]
    }
   ],
   "source": [
    "tot_space = 20\n",
    "print('-' * 10, 'NUMBER OF TOTAL LABEL OCCURENCES: TESTING', '-' * 10, '\\n')\n",
    "for label in LABELS: \n",
    "    num_instances = find_label_instances(deberta_test, label2id[label])\n",
    "    print(label, ' ' * (tot_space - len(label)) + ':', num_instances)\n",
    "    \n",
    "print('\\n')\n",
    "print('-' * 10, 'NUMBER OF LABEL OCCURENCES: TESTING', '-' * 10, '\\n')\n",
    "for label in LABELS: \n",
    "    num_documents = find_label_number(deberta_test, label2id[label])\n",
    "    print(label, ' ' * (tot_space - len(label)) + ':', num_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T23:46:07.943947Z",
     "iopub.status.busy": "2024-04-30T23:46:07.943581Z",
     "iopub.status.idle": "2024-04-30T23:46:47.492717Z",
     "shell.execute_reply": "2024-04-30T23:46:47.491666Z",
     "shell.execute_reply.started": "2024-04-30T23:46:07.943921Z"
    }
   },
   "outputs": [],
   "source": [
    "roberta_train.to_csv(\"roberta_train.csv\", index=False)\n",
    "roberta_test.to_csv(\"roberta_test.csv\", index = False)\n",
    "deberta_train.to_csv(\"deberta_train.csv\", index=False)\n",
    "deberta_test.to_csv(\"deberta_test.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
