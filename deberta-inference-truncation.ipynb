{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeBERTa Inference Notebook for Truncation\n",
    "This notebook serves as the main runfile for making inferences on DeBERTa models using truncation. The parameters that can be changed are the threshold for determining if something is a non-PII or not as well as how the data is truncated. Otherwise, make sure to import the correct model path for the most updated DeBERTa truncation model\n",
    "\n",
    "Note that we tested models by making inferences and submitting these inferences to kaggle for scoring.\n",
    "\n",
    "To replicate the baseline, change truncation = True when tokenizing (as well as other changes made in model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-02T22:36:21.274932Z",
     "iopub.status.busy": "2024-05-02T22:36:21.274342Z",
     "iopub.status.idle": "2024-05-02T22:36:22.467847Z",
     "shell.execute_reply": "2024-05-02T22:36:22.466832Z",
     "shell.execute_reply.started": "2024-05-02T22:36:21.274881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/roberta-model-partition/__results__.html\n",
      "/kaggle/input/roberta-model-partition/__notebook__.ipynb\n",
      "/kaggle/input/roberta-model-partition/__output__.json\n",
      "/kaggle/input/roberta-model-partition/custom.css\n",
      "/kaggle/input/roberta-model-partition/roberta_partition/config.json\n",
      "/kaggle/input/roberta-model-partition/roberta_partition/merges.txt\n",
      "/kaggle/input/roberta-model-partition/roberta_partition/training_args.bin\n",
      "/kaggle/input/roberta-model-partition/roberta_partition/tokenizer.json\n",
      "/kaggle/input/roberta-model-partition/roberta_partition/vocab.json\n",
      "/kaggle/input/roberta-model-partition/roberta_partition/tokenizer_config.json\n",
      "/kaggle/input/roberta-model-partition/roberta_partition/model.safetensors\n",
      "/kaggle/input/roberta-model-partition/roberta_partition/special_tokens_map.json\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/config.json\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/merges.txt\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/trainer_state.json\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/training_args.bin\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/tokenizer.json\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/vocab.json\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/tokenizer_config.json\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/scheduler.pt\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/model.safetensors\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/special_tokens_map.json\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/optimizer.pt\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/rng_state.pth\n",
      "/kaggle/input/roberta-model-partition/roberta_partitione/merges.txt\n",
      "/kaggle/input/roberta-model-partition/roberta_partitione/tokenizer.json\n",
      "/kaggle/input/roberta-model-partition/roberta_partitione/vocab.json\n",
      "/kaggle/input/roberta-model-partition/roberta_partitione/tokenizer_config.json\n",
      "/kaggle/input/roberta-model-partition/roberta_partitione/special_tokens_map.json\n",
      "/kaggle/input/pii-detection-removal-from-educational-data/sample_submission.csv\n",
      "/kaggle/input/pii-detection-removal-from-educational-data/train.json\n",
      "/kaggle/input/pii-detection-removal-from-educational-data/test.json\n",
      "/kaggle/input/deberta-model-truncation/__results__.html\n",
      "/kaggle/input/deberta-model-truncation/__notebook__.ipynb\n",
      "/kaggle/input/deberta-model-truncation/__output__.json\n",
      "/kaggle/input/deberta-model-truncation/custom.css\n",
      "/kaggle/input/deberta-model-truncation/output/checkpoint-1500/spm.model\n",
      "/kaggle/input/deberta-model-truncation/output/checkpoint-1500/config.json\n",
      "/kaggle/input/deberta-model-truncation/output/checkpoint-1500/trainer_state.json\n",
      "/kaggle/input/deberta-model-truncation/output/checkpoint-1500/training_args.bin\n",
      "/kaggle/input/deberta-model-truncation/output/checkpoint-1500/tokenizer.json\n",
      "/kaggle/input/deberta-model-truncation/output/checkpoint-1500/tokenizer_config.json\n",
      "/kaggle/input/deberta-model-truncation/output/checkpoint-1500/scheduler.pt\n",
      "/kaggle/input/deberta-model-truncation/output/checkpoint-1500/model.safetensors\n",
      "/kaggle/input/deberta-model-truncation/output/checkpoint-1500/special_tokens_map.json\n",
      "/kaggle/input/deberta-model-truncation/output/checkpoint-1500/optimizer.pt\n",
      "/kaggle/input/deberta-model-truncation/output/checkpoint-1500/rng_state.pth\n",
      "/kaggle/input/deberta-model-truncation/output/checkpoint-1500/added_tokens.json\n",
      "/kaggle/input/deberta-model-truncation/deberta_opttrunc1/spm.model\n",
      "/kaggle/input/deberta-model-truncation/deberta_opttrunc1/config.json\n",
      "/kaggle/input/deberta-model-truncation/deberta_opttrunc1/training_args.bin\n",
      "/kaggle/input/deberta-model-truncation/deberta_opttrunc1/tokenizer.json\n",
      "/kaggle/input/deberta-model-truncation/deberta_opttrunc1/tokenizer_config.json\n",
      "/kaggle/input/deberta-model-truncation/deberta_opttrunc1/model.safetensors\n",
      "/kaggle/input/deberta-model-truncation/deberta_opttrunc1/special_tokens_map.json\n",
      "/kaggle/input/deberta-model-truncation/deberta_opttrunc1/added_tokens.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T22:36:22.470050Z",
     "iopub.status.busy": "2024-05-02T22:36:22.469653Z",
     "iopub.status.idle": "2024-05-02T22:36:22.474325Z",
     "shell.execute_reply": "2024-05-02T22:36:22.473403Z",
     "shell.execute_reply.started": "2024-05-02T22:36:22.470024Z"
    }
   },
   "outputs": [],
   "source": [
    "INFERENCE_MAX_LENGTH = 2048\n",
    "model_path = '/kaggle/input/deberta-model-truncation/deberta_opttrunc1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T22:36:22.479203Z",
     "iopub.status.busy": "2024-05-02T22:36:22.478885Z",
     "iopub.status.idle": "2024-05-02T22:36:43.163836Z",
     "shell.execute_reply": "2024-05-02T22:36:43.163044Z",
     "shell.execute_reply.started": "2024-05-02T22:36:22.479178Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 22:36:33.526981: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-02 22:36:33.527095: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-02 22:36:33.700420: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import argparse\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification\n",
    "from datasets import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T22:36:43.166615Z",
     "iopub.status.busy": "2024-05-02T22:36:43.166056Z",
     "iopub.status.idle": "2024-05-02T22:36:43.181797Z",
     "shell.execute_reply": "2024-05-02T22:36:43.180649Z",
     "shell.execute_reply.started": "2024-05-02T22:36:43.166588Z"
    }
   },
   "outputs": [],
   "source": [
    "data = json.load(open(\"/kaggle/input/pii-detection-removal-from-educational-data/test.json\"))\n",
    "df_test = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T22:36:43.183678Z",
     "iopub.status.busy": "2024-05-02T22:36:43.183295Z",
     "iopub.status.idle": "2024-05-02T22:36:43.207043Z",
     "shell.execute_reply": "2024-05-02T22:36:43.206271Z",
     "shell.execute_reply.started": "2024-05-02T22:36:43.183643Z"
    }
   },
   "outputs": [],
   "source": [
    "def reconstruct(batch): \n",
    "    text = []\n",
    "    token_map = []\n",
    "    \n",
    "    idx = 0\n",
    "    \n",
    "    for t, ws in zip(batch[\"tokens\"], batch[\"trailing_whitespace\"]):\n",
    "    \n",
    "        text.append(t)\n",
    "        token_map.extend([idx]*len(t))\n",
    "        if ws:\n",
    "            text.append(\" \")\n",
    "            token_map.append(-1)\n",
    "        \n",
    "        idx += 1\n",
    "            \n",
    "                \n",
    "    return text, token_map\n",
    "\n",
    "def tokenize(batch, tokenizer):\n",
    "    \n",
    "    text,token_map = reconstruct(batch)\n",
    "    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, truncation=False, max_length=INFERENCE_MAX_LENGTH)\n",
    "    \n",
    "    # TRUNCATE: VARIOUS CUTOFFS\n",
    "    # LINE 1: SAME CUTOFF AS TRAINING (MODULO DIFFERENT LENGTH)\n",
    "    # LINE 2: BEST CUTOFF FOR INFERENCE_MAX_LENGTH\n",
    "    length = len(tokenized.input_ids)\n",
    "    if (length > INFERENCE_MAX_LENGTH):\n",
    "        for k,v in tokenized.items():\n",
    "            # tokenized[k] = v[:175] + v[-(INFERENCE_MAX_LENGTH - 175):]\n",
    "            tokenized[k] = v[:1024] + v[-(INFERENCE_MAX_LENGTH - 1024):]    \n",
    "\n",
    "    return tokenized.input_ids, tokenized.attention_mask, tokenized.offset_mapping, token_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T22:36:43.208400Z",
     "iopub.status.busy": "2024-05-02T22:36:43.208134Z",
     "iopub.status.idle": "2024-05-02T22:36:43.627172Z",
     "shell.execute_reply": "2024-05-02T22:36:43.626203Z",
     "shell.execute_reply.started": "2024-05-02T22:36:43.208377Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "df_test[['input_ids', 'attention_mask', 'offset_mapping', 'token_map']] = df_test.apply(lambda row: tokenize(row, tokenizer), axis='columns', result_type='expand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T22:36:43.628510Z",
     "iopub.status.busy": "2024-05-02T22:36:43.628202Z",
     "iopub.status.idle": "2024-05-02T22:36:43.690557Z",
     "shell.execute_reply": "2024-05-02T22:36:43.689637Z",
     "shell.execute_reply.started": "2024-05-02T22:36:43.628485Z"
    }
   },
   "outputs": [],
   "source": [
    "ds =  Dataset.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T22:36:43.691958Z",
     "iopub.status.busy": "2024-05-02T22:36:43.691713Z",
     "iopub.status.idle": "2024-05-02T22:36:49.609409Z",
     "shell.execute_reply": "2024-05-02T22:36:49.608410Z",
     "shell.execute_reply.started": "2024-05-02T22:36:43.691937Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)\n",
    "args = TrainingArguments(\n",
    "    \".\", \n",
    "    per_device_eval_batch_size=1, \n",
    "    report_to=\"none\",\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=args, \n",
    "    data_collator=collator, \n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T22:36:49.611050Z",
     "iopub.status.busy": "2024-05-02T22:36:49.610676Z",
     "iopub.status.idle": "2024-05-02T22:36:54.086104Z",
     "shell.execute_reply": "2024-05-02T22:36:54.085280Z",
     "shell.execute_reply.started": "2024-05-02T22:36:49.611006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(ds).predictions\n",
    "pred_softmax = np.exp(predictions) / np.sum(np.exp(predictions), axis = 2).reshape(predictions.shape[0],predictions.shape[1],1)\n",
    "\n",
    "config = json.load(open(Path(model_path) / \"config.json\"))\n",
    "id2label = config[\"id2label\"]\n",
    "preds = predictions.argmax(-1)\n",
    "preds_without_O = pred_softmax[:,:,:12].argmax(-1)\n",
    "O_preds = pred_softmax[:,:,12]\n",
    "\n",
    "threshold = 0.99\n",
    "preds_final = np.where(O_preds < threshold, preds_without_O , preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T22:36:54.087517Z",
     "iopub.status.busy": "2024-05-02T22:36:54.087200Z",
     "iopub.status.idle": "2024-05-02T22:36:54.190474Z",
     "shell.execute_reply": "2024-05-02T22:36:54.189475Z",
     "shell.execute_reply.started": "2024-05-02T22:36:54.087493Z"
    }
   },
   "outputs": [],
   "source": [
    "triplets = []\n",
    "document, token, label, token_str = [], [], [], []\n",
    "for p, token_map, offsets, tokens, doc in zip(preds_final, ds[\"token_map\"], ds[\"offset_mapping\"], ds[\"tokens\"], ds[\"document\"]):\n",
    "\n",
    "    for token_pred, (start_idx, end_idx) in zip(p, offsets):\n",
    "        label_pred = id2label[str(token_pred)]\n",
    "\n",
    "        if start_idx + end_idx == 0: continue\n",
    "\n",
    "        if token_map[start_idx] == -1:\n",
    "            start_idx += 1\n",
    "\n",
    "        # ignore \"\\n\\n\"\n",
    "        while start_idx < len(token_map) and tokens[token_map[start_idx]].isspace():\n",
    "            start_idx += 1\n",
    "\n",
    "        if start_idx >= len(token_map): break\n",
    "\n",
    "        token_id = token_map[start_idx]\n",
    "\n",
    "        # ignore \"O\" predictions and whitespace preds\n",
    "        if label_pred != \"O\" and token_id != -1:\n",
    "            triplet = (label_pred, token_id, tokens[token_id])\n",
    "\n",
    "            if triplet not in triplets:\n",
    "                document.append(doc)\n",
    "                token.append(token_id)\n",
    "                label.append(label_pred)\n",
    "                token_str.append(tokens[token_id])\n",
    "                triplets.append(triplet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T02:08:48.681877Z",
     "iopub.status.busy": "2024-04-30T02:08:48.681371Z",
     "iopub.status.idle": "2024-04-30T02:08:48.690567Z",
     "shell.execute_reply": "2024-04-30T02:08:48.689223Z",
     "shell.execute_reply.started": "2024-04-30T02:08:48.681839Z"
    }
   },
   "source": [
    "# Prepare Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T22:36:54.191841Z",
     "iopub.status.busy": "2024-05-02T22:36:54.191546Z",
     "iopub.status.idle": "2024-05-02T22:36:54.211842Z",
     "shell.execute_reply": "2024-05-02T22:36:54.210862Z",
     "shell.execute_reply.started": "2024-05-02T22:36:54.191817Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>token_str</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>482</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>483</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>741</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>742</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Diego</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Estrada</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>464</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Diego</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>465</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Estrada</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Gilberto</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Gamboa</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Sindy</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Samaca</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nadine</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Born</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>86</td>\n",
       "      <td>6</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Eladio</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>86</td>\n",
       "      <td>7</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Amaya</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Silvia</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Villalobos</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>104</td>\n",
       "      <td>8</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Sakir</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>104</td>\n",
       "      <td>9</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Ahmad</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Francisco</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>112</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Ferreira</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>123</td>\n",
       "      <td>32</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Stefano</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>123</td>\n",
       "      <td>33</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Lovato</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    document  token           label   token_str  row_id\n",
       "0          7      9  B-NAME_STUDENT    Nathalie       0\n",
       "1          7     10  I-NAME_STUDENT       Sylla       1\n",
       "2          7    482  B-NAME_STUDENT    Nathalie       2\n",
       "3          7    483  I-NAME_STUDENT       Sylla       3\n",
       "4          7    741  B-NAME_STUDENT    Nathalie       4\n",
       "5          7    742  I-NAME_STUDENT       Sylla       5\n",
       "6         10      0  B-NAME_STUDENT       Diego       6\n",
       "7         10      1  I-NAME_STUDENT     Estrada       7\n",
       "8         10    464  B-NAME_STUDENT       Diego       8\n",
       "9         10    465  I-NAME_STUDENT     Estrada       9\n",
       "10        16      4  B-NAME_STUDENT    Gilberto      10\n",
       "11        16      5  I-NAME_STUDENT      Gamboa      11\n",
       "12        20      5  B-NAME_STUDENT       Sindy      12\n",
       "13        20      6  I-NAME_STUDENT      Samaca      13\n",
       "14        56     12  B-NAME_STUDENT      Nadine      14\n",
       "15        56     13  I-NAME_STUDENT        Born      15\n",
       "16        86      6  B-NAME_STUDENT      Eladio      16\n",
       "17        86      7  I-NAME_STUDENT       Amaya      17\n",
       "18        93      0  B-NAME_STUDENT      Silvia      18\n",
       "19        93      1  I-NAME_STUDENT  Villalobos      19\n",
       "20       104      8  B-NAME_STUDENT       Sakir      20\n",
       "21       104      9  I-NAME_STUDENT       Ahmad      21\n",
       "22       112      5  B-NAME_STUDENT   Francisco      22\n",
       "23       112      6  I-NAME_STUDENT    Ferreira      23\n",
       "24       123     32  B-NAME_STUDENT     Stefano      24\n",
       "25       123     33  I-NAME_STUDENT      Lovato      25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"document\": document,\n",
    "    \"token\": token,\n",
    "    \"label\": label,\n",
    "    \"token_str\": token_str\n",
    "})\n",
    "df[\"row_id\"] = list(range(len(df)))\n",
    "display(df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T22:36:54.213116Z",
     "iopub.status.busy": "2024-05-02T22:36:54.212857Z",
     "iopub.status.idle": "2024-05-02T22:36:54.227173Z",
     "shell.execute_reply": "2024-05-02T22:36:54.226270Z",
     "shell.execute_reply.started": "2024-05-02T22:36:54.213092Z"
    }
   },
   "outputs": [],
   "source": [
    "df[[\"row_id\", \"document\", \"token\", \"label\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    },
    {
     "sourceId": 175087285,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 175322202,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
