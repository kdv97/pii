{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0377666b",
   "metadata": {},
   "source": [
    "# RoBERTa Inference Notebook for Partitioning\n",
    "This notebook serves as the main runfile for making inferences on RoBERTa models using partitioning. The parameters that can be changed are the threshold for determining if something is a non-PII or not. Otherwise, make sure to import the correct model path for the most updated RoBERTa partitioning model\n",
    "\n",
    "Note that we tested models by making inferences and submitting these inferences to kaggle for scoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c323ac4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-01T15:59:07.619074Z",
     "iopub.status.busy": "2024-05-01T15:59:07.618683Z",
     "iopub.status.idle": "2024-05-01T15:59:08.336089Z",
     "shell.execute_reply": "2024-05-01T15:59:08.335151Z"
    },
    "papermill": {
     "duration": 0.727048,
     "end_time": "2024-05-01T15:59:08.338434",
     "exception": false,
     "start_time": "2024-05-01T15:59:07.611386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/roberta-model-partition/__results__.html\n",
      "/kaggle/input/roberta-model-partition/__notebook__.ipynb\n",
      "/kaggle/input/roberta-model-partition/__output__.json\n",
      "/kaggle/input/roberta-model-partition/custom.css\n",
      "/kaggle/input/roberta-model-partition/roberta_partition/config.json\n",
      "/kaggle/input/roberta-model-partition/roberta_partition/merges.txt\n",
      "/kaggle/input/roberta-model-partition/roberta_partition/training_args.bin\n",
      "/kaggle/input/roberta-model-partition/roberta_partition/tokenizer.json\n",
      "/kaggle/input/roberta-model-partition/roberta_partition/vocab.json\n",
      "/kaggle/input/roberta-model-partition/roberta_partition/tokenizer_config.json\n",
      "/kaggle/input/roberta-model-partition/roberta_partition/model.safetensors\n",
      "/kaggle/input/roberta-model-partition/roberta_partition/special_tokens_map.json\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/config.json\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/merges.txt\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/trainer_state.json\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/training_args.bin\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/tokenizer.json\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/vocab.json\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/tokenizer_config.json\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/scheduler.pt\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/model.safetensors\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/special_tokens_map.json\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/optimizer.pt\n",
      "/kaggle/input/roberta-model-partition/output/checkpoint-3000/rng_state.pth\n",
      "/kaggle/input/roberta-model-partition/roberta_partitione/merges.txt\n",
      "/kaggle/input/roberta-model-partition/roberta_partitione/tokenizer.json\n",
      "/kaggle/input/roberta-model-partition/roberta_partitione/vocab.json\n",
      "/kaggle/input/roberta-model-partition/roberta_partitione/tokenizer_config.json\n",
      "/kaggle/input/roberta-model-partition/roberta_partitione/special_tokens_map.json\n",
      "/kaggle/input/pii-detection-removal-from-educational-data/sample_submission.csv\n",
      "/kaggle/input/pii-detection-removal-from-educational-data/train.json\n",
      "/kaggle/input/pii-detection-removal-from-educational-data/test.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aafb6d12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:59:08.350566Z",
     "iopub.status.busy": "2024-05-01T15:59:08.349842Z",
     "iopub.status.idle": "2024-05-01T15:59:08.353862Z",
     "shell.execute_reply": "2024-05-01T15:59:08.353014Z"
    },
    "papermill": {
     "duration": 0.011623,
     "end_time": "2024-05-01T15:59:08.355701",
     "exception": false,
     "start_time": "2024-05-01T15:59:08.344078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INFERENCE_MAX_LENGTH = 512\n",
    "model_path = '/kaggle/input/roberta-model-partition/roberta_partition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d2d94b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:59:08.366506Z",
     "iopub.status.busy": "2024-05-01T15:59:08.366221Z",
     "iopub.status.idle": "2024-05-01T15:59:24.864242Z",
     "shell.execute_reply": "2024-05-01T15:59:24.863187Z"
    },
    "papermill": {
     "duration": 16.506115,
     "end_time": "2024-05-01T15:59:24.866654",
     "exception": false,
     "start_time": "2024-05-01T15:59:08.360539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 15:59:17.170979: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-01 15:59:17.171076: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-01 15:59:17.240018: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import argparse\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification\n",
    "from datasets import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "292dfe02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:59:24.878389Z",
     "iopub.status.busy": "2024-05-01T15:59:24.877838Z",
     "iopub.status.idle": "2024-05-01T15:59:24.893799Z",
     "shell.execute_reply": "2024-05-01T15:59:24.892967Z"
    },
    "papermill": {
     "duration": 0.023777,
     "end_time": "2024-05-01T15:59:24.895678",
     "exception": false,
     "start_time": "2024-05-01T15:59:24.871901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = json.load(open(\"/kaggle/input/pii-detection-removal-from-educational-data/test.json\"))\n",
    "df_test = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d70547b",
   "metadata": {},
   "source": [
    "# Tokenize & Partition Text\n",
    "Note that this is an analagous tokenizer to the data-exploration file, however, as we do not know the labels we instead add a token_map which maps each token to the appropriate word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cebde42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:59:24.907157Z",
     "iopub.status.busy": "2024-05-01T15:59:24.906406Z",
     "iopub.status.idle": "2024-05-01T15:59:24.913765Z",
     "shell.execute_reply": "2024-05-01T15:59:24.912906Z"
    },
    "papermill": {
     "duration": 0.015011,
     "end_time": "2024-05-01T15:59:24.915641",
     "exception": false,
     "start_time": "2024-05-01T15:59:24.900630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reconstruct(batch): \n",
    "    text = []\n",
    "    token_map = []\n",
    "    \n",
    "    idx = 0\n",
    "    \n",
    "    for t, ws in zip(batch[\"tokens\"], batch[\"trailing_whitespace\"]):\n",
    "    \n",
    "        text.append(t)\n",
    "        token_map.extend([idx]*len(t))\n",
    "        if ws:\n",
    "            text.append(\" \")\n",
    "            token_map.append(-1)\n",
    "        \n",
    "        idx += 1\n",
    "            \n",
    "                \n",
    "    return text, token_map\n",
    "\n",
    "def tokenize(batch, tokenizer):\n",
    "    \n",
    "    text,token_map = reconstruct(batch)\n",
    "    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, truncation=False, max_length=INFERENCE_MAX_LENGTH)\n",
    "\n",
    "    return tokenized.input_ids, tokenized.attention_mask, tokenized.offset_mapping, token_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "572eb782",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:59:24.926753Z",
     "iopub.status.busy": "2024-05-01T15:59:24.926245Z",
     "iopub.status.idle": "2024-05-01T15:59:24.934729Z",
     "shell.execute_reply": "2024-05-01T15:59:24.933881Z"
    },
    "papermill": {
     "duration": 0.016081,
     "end_time": "2024-05-01T15:59:24.936676",
     "exception": false,
     "start_time": "2024-05-01T15:59:24.920595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_files(df, MAX_LENGTH): \n",
    "    df_split = pd.DataFrame(columns = ['document', 'full_text', 'tokens', 'trailing_whitespace', 'input_ids', 'attention_mask', 'offset_mapping', 'token_map'])\n",
    "\n",
    "    for index, row in df.iterrows(): \n",
    "        document = df.loc[index].document\n",
    "        full_text = df.loc[index].full_text\n",
    "        tokens = df.loc[index].tokens\n",
    "        trailing_whitespace = df.loc[index].trailing_whitespace\n",
    "        input_ids = df.loc[index].input_ids\n",
    "        attention_mask = df.loc[index].attention_mask\n",
    "        offset_mapping = df.loc[index].offset_mapping\n",
    "        token_map = df.loc[index].token_map\n",
    "        length = len(input_ids)\n",
    "        num_rows = -(length // -MAX_LENGTH)       \n",
    "        for i in range(num_rows): \n",
    "            new_input_ids = input_ids[i*MAX_LENGTH: (i + 1)* MAX_LENGTH]\n",
    "            new_attention_mask = attention_mask[i*MAX_LENGTH: (i + 1)* MAX_LENGTH]\n",
    "            new_offset_mapping = offset_mapping[i*MAX_LENGTH: (i + 1)* MAX_LENGTH]\n",
    "            df_split = df_split._append({'document': document, 'full_text': full_text, 'tokens': tokens, 'trailing_whitespace': trailing_whitespace, 'input_ids': new_input_ids, 'attention_mask': new_attention_mask, 'offset_mapping': new_offset_mapping, 'token_map': token_map}, ignore_index=True)\n",
    "    \n",
    "    return df_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8348db84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:59:24.947662Z",
     "iopub.status.busy": "2024-05-01T15:59:24.947367Z",
     "iopub.status.idle": "2024-05-01T15:59:25.183321Z",
     "shell.execute_reply": "2024-05-01T15:59:25.182514Z"
    },
    "papermill": {
     "duration": 0.244143,
     "end_time": "2024-05-01T15:59:25.185719",
     "exception": false,
     "start_time": "2024-05-01T15:59:24.941576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "df_test[['input_ids', 'attention_mask', 'offset_mapping', 'token_map']] = df_test.apply(lambda row: tokenize(row, tokenizer), axis='columns', result_type='expand')\n",
    "df_tt = split_files(df_test, INFERENCE_MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f64dfe",
   "metadata": {
    "papermill": {
     "duration": 0.004748,
     "end_time": "2024-05-01T15:59:25.195752",
     "exception": false,
     "start_time": "2024-05-01T15:59:25.191004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db295edb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:59:25.206973Z",
     "iopub.status.busy": "2024-05-01T15:59:25.206670Z",
     "iopub.status.idle": "2024-05-01T15:59:25.272600Z",
     "shell.execute_reply": "2024-05-01T15:59:25.271899Z"
    },
    "papermill": {
     "duration": 0.074035,
     "end_time": "2024-05-01T15:59:25.274726",
     "exception": false,
     "start_time": "2024-05-01T15:59:25.200691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds =  Dataset.from_pandas(df_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5058e12f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:59:25.286401Z",
     "iopub.status.busy": "2024-05-01T15:59:25.286099Z",
     "iopub.status.idle": "2024-05-01T15:59:28.973137Z",
     "shell.execute_reply": "2024-05-01T15:59:28.972327Z"
    },
    "papermill": {
     "duration": 3.695505,
     "end_time": "2024-05-01T15:59:28.975441",
     "exception": false,
     "start_time": "2024-05-01T15:59:25.279936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)\n",
    "args = TrainingArguments(\n",
    "    \".\", \n",
    "    per_device_eval_batch_size=1, \n",
    "    report_to=\"none\",\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=args, \n",
    "    data_collator=collator, \n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "245d1e07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:59:28.987710Z",
     "iopub.status.busy": "2024-05-01T15:59:28.987371Z",
     "iopub.status.idle": "2024-05-01T15:59:33.804192Z",
     "shell.execute_reply": "2024-05-01T15:59:33.803385Z"
    },
    "papermill": {
     "duration": 4.825298,
     "end_time": "2024-05-01T15:59:33.806391",
     "exception": false,
     "start_time": "2024-05-01T15:59:28.981093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(ds).predictions\n",
    "pred_softmax = np.exp(predictions) / np.sum(np.exp(predictions), axis = 2).reshape(predictions.shape[0],predictions.shape[1],1)\n",
    "\n",
    "config = json.load(open(Path(model_path) / \"config.json\"))\n",
    "id2label = config[\"id2label\"]\n",
    "preds = predictions.argmax(-1)\n",
    "preds_without_O = pred_softmax[:,:,:12].argmax(-1)\n",
    "O_preds = pred_softmax[:,:,12]\n",
    "\n",
    "threshold = 0.9\n",
    "preds_final = np.where(O_preds < threshold, preds_without_O , preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b8287b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:59:33.821367Z",
     "iopub.status.busy": "2024-05-01T15:59:33.820647Z",
     "iopub.status.idle": "2024-05-01T15:59:34.003588Z",
     "shell.execute_reply": "2024-05-01T15:59:34.002680Z"
    },
    "papermill": {
     "duration": 0.192781,
     "end_time": "2024-05-01T15:59:34.005878",
     "exception": false,
     "start_time": "2024-05-01T15:59:33.813097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "triplets = []\n",
    "document, token, label, token_str = [], [], [], []\n",
    "for p, token_map, offsets, tokens, doc in zip(preds_final, ds[\"token_map\"], ds[\"offset_mapping\"], ds[\"tokens\"], ds[\"document\"]):\n",
    "\n",
    "    for token_pred, (start_idx, end_idx) in zip(p, offsets):\n",
    "        label_pred = id2label[str(token_pred)]\n",
    "\n",
    "        if start_idx + end_idx == 0: continue\n",
    "\n",
    "        if token_map[start_idx] == -1:\n",
    "            start_idx += 1\n",
    "\n",
    "        # ignore \"\\n\\n\"\n",
    "        while start_idx < len(token_map) and tokens[token_map[start_idx]].isspace():\n",
    "            start_idx += 1\n",
    "\n",
    "        if start_idx >= len(token_map): break\n",
    "\n",
    "        token_id = token_map[start_idx]\n",
    "\n",
    "        # ignore \"O\" predictions and whitespace preds\n",
    "        if label_pred != \"O\" and token_id != -1:\n",
    "            triplet = (label_pred, token_id, tokens[token_id])\n",
    "\n",
    "            if triplet not in triplets:\n",
    "                document.append(doc)\n",
    "                token.append(token_id)\n",
    "                label.append(label_pred)\n",
    "                token_str.append(tokens[token_id])\n",
    "                triplets.append(triplet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb5a80a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T02:08:48.681877Z",
     "iopub.status.busy": "2024-04-30T02:08:48.681371Z",
     "iopub.status.idle": "2024-04-30T02:08:48.690567Z",
     "shell.execute_reply": "2024-04-30T02:08:48.689223Z",
     "shell.execute_reply.started": "2024-04-30T02:08:48.681839Z"
    },
    "papermill": {
     "duration": 0.005428,
     "end_time": "2024-05-01T15:59:34.016657",
     "exception": false,
     "start_time": "2024-05-01T15:59:34.011229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3073b555",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:59:34.028440Z",
     "iopub.status.busy": "2024-05-01T15:59:34.027909Z",
     "iopub.status.idle": "2024-05-01T15:59:34.045332Z",
     "shell.execute_reply": "2024-05-01T15:59:34.044521Z"
    },
    "papermill": {
     "duration": 0.025627,
     "end_time": "2024-05-01T15:59:34.047510",
     "exception": false,
     "start_time": "2024-05-01T15:59:34.021883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>token_str</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Avril</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>482</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>483</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>741</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>742</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Diego</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Estrada</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>464</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Diego</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>465</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Estrada</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Gilberto</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Gamboa</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Sindy</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Samaca</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nadine</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Born</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>86</td>\n",
       "      <td>6</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Eladio</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>86</td>\n",
       "      <td>7</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Amaya</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Silvia</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Villalobos</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>104</td>\n",
       "      <td>8</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Sakir</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>104</td>\n",
       "      <td>9</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Ahmad</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Francisco</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>112</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Ferreira</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>123</td>\n",
       "      <td>32</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Stefano</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>123</td>\n",
       "      <td>33</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Lovato</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    document  token           label   token_str  row_id\n",
       "0          7      6  B-NAME_STUDENT       Avril       0\n",
       "1          7      9  B-NAME_STUDENT    Nathalie       1\n",
       "2          7     10  I-NAME_STUDENT       Sylla       2\n",
       "3          7    482  B-NAME_STUDENT    Nathalie       3\n",
       "4          7    483  I-NAME_STUDENT       Sylla       4\n",
       "5          7    741  B-NAME_STUDENT    Nathalie       5\n",
       "6          7    742  I-NAME_STUDENT       Sylla       6\n",
       "7         10      0  B-NAME_STUDENT       Diego       7\n",
       "8         10      1  I-NAME_STUDENT     Estrada       8\n",
       "9         10    464  B-NAME_STUDENT       Diego       9\n",
       "10        10    465  I-NAME_STUDENT     Estrada      10\n",
       "11        16      4  B-NAME_STUDENT    Gilberto      11\n",
       "12        16      5  I-NAME_STUDENT      Gamboa      12\n",
       "13        20      5  B-NAME_STUDENT       Sindy      13\n",
       "14        20      6  I-NAME_STUDENT      Samaca      14\n",
       "15        56     12  B-NAME_STUDENT      Nadine      15\n",
       "16        56     13  I-NAME_STUDENT        Born      16\n",
       "17        86      6  B-NAME_STUDENT      Eladio      17\n",
       "18        86      7  I-NAME_STUDENT       Amaya      18\n",
       "19        93      0  B-NAME_STUDENT      Silvia      19\n",
       "20        93      1  I-NAME_STUDENT  Villalobos      20\n",
       "21       104      8  B-NAME_STUDENT       Sakir      21\n",
       "22       104      9  I-NAME_STUDENT       Ahmad      22\n",
       "23       112      5  B-NAME_STUDENT   Francisco      23\n",
       "24       112      6  I-NAME_STUDENT    Ferreira      24\n",
       "25       123     32  B-NAME_STUDENT     Stefano      25\n",
       "26       123     33  I-NAME_STUDENT      Lovato      26"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"document\": document,\n",
    "    \"token\": token,\n",
    "    \"label\": label,\n",
    "    \"token_str\": token_str\n",
    "})\n",
    "df[\"row_id\"] = list(range(len(df)))\n",
    "display(df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae7b74df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:59:34.060446Z",
     "iopub.status.busy": "2024-05-01T15:59:34.059822Z",
     "iopub.status.idle": "2024-05-01T15:59:34.072851Z",
     "shell.execute_reply": "2024-05-01T15:59:34.071943Z"
    },
    "papermill": {
     "duration": 0.021426,
     "end_time": "2024-05-01T15:59:34.074817",
     "exception": false,
     "start_time": "2024-05-01T15:59:34.053391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[[\"row_id\", \"document\", \"token\", \"label\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c86949",
   "metadata": {
    "papermill": {
     "duration": 0.005485,
     "end_time": "2024-05-01T15:59:34.087550",
     "exception": false,
     "start_time": "2024-05-01T15:59:34.082065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    },
    {
     "sourceId": 175069967,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32.152706,
   "end_time": "2024-05-01T15:59:37.017546",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-01T15:59:04.864840",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
